{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------ Install Chroma and Google Gen AI ------------------------------\n",
        "#!pip install chromadb\n",
        "#!pip install google-generativeai"
      ],
      "metadata": {
        "id": "30iA5dB1vb72"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------ Setup ------------------------------\n",
        "\n",
        "import os\n",
        "import chromadb.utils.embedding_functions as embedding_functions\n",
        "import chromadb\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "google_ef = embedding_functions.GoogleGenerativeAiEmbeddingFunction(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-pro\")"
      ],
      "metadata": {
        "id": "qiMNVkCqxDt8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "I3x56Roj03Bs",
        "outputId": "dc2c9c77-5cc6-4c79-f7bd-775eb8c6a717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-001\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------ Functions ------------------------------\n",
        "\n",
        "for m in genai.list_models():\n",
        "    if \"embedContent\" in m.supported_generation_methods:\n",
        "        print(m.name)\n",
        "\n",
        "def build_prompt(query, context):\n",
        "    base_prompt = {\n",
        "        \"content\": \"I am going to ask you a question, which I would like you to answer\"\n",
        "        \" based only on the provided context, and not any other information.\"\n",
        "        \" If there is not enough information in the context to answer the question,\"\n",
        "        ' say \"I am not sure\", then try to make a guess.'\n",
        "        \" If there is enough information, do not mention the word context\",\n",
        "    }\n",
        "    user_prompt = {\n",
        "        \"content\": f\" The question is '{query}'. Here is all the context you have:\"\n",
        "        f'{(\" \").join(context)}',\n",
        "    }\n",
        "\n",
        "    # combine the prompts to output a single prompt string\n",
        "    system = f\"{base_prompt['content']} {user_prompt['content']}\"\n",
        "\n",
        "    return system\n",
        "\n",
        "\n",
        "def get_gemini_response(query, context):\n",
        "    response = model.generate_content(build_prompt(query, context))\n",
        "    return response.text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------ Create Chroma Client and Collection ------------------------------\n",
        "\n",
        "\n",
        "# Create a client\n",
        "client = chromadb.Client()\n",
        "\n",
        "nokia_collection = client.get_or_create_collection(name=\"nokia\", embedding_function=google_ef)\n",
        "\n",
        "\n",
        "# Add documents\n",
        "nokia_collection.add(\n",
        "    documents=[\"Nokia on Thursday said that it will begin a two-year 600 million euro ($653 million) share buyback this quarter, after reporting that its profit plunged in 2023.\",\n",
        "               \"Nokia shares were 7% higher at around 8.19 a.m. London time on Thursday.\",\n",
        "               \"One of the world’s largest mobile network equipment makers, Nokia posted fourth-quarter net sales of 5.7 billion euros, a 23% year-on-year decline. Comparable operating profit fell 27% year-on-year to 846 million.\",\n",
        "               \"“In 2023 we saw a meaningful shift in customer behavior impacting our industry driven by the macro-economic environment and high interest rates along with customer inventory digestion,” Nokia CEO Pekka Lundmark said in a statement.\"],\n",
        "    metadatas=[{\"source\": \"my_source\"}, {\"source\": \"my_source\"}, {\"source\": \"my_source\"}, {\"source\": \"my_source\"}],\n",
        "    ids=[\"id1\", \"id2\", \"id3\", \"id4\"],\n",
        ")\n",
        "\n",
        "# Query\n",
        "nokia_collection = client.get_collection(name=\"nokia\", embedding_function=google_ef)\n"
      ],
      "metadata": {
        "id": "EctwYBERxPEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------ Query and results ------------------------------\n",
        "\n",
        "# Successful querys\n",
        "# query = \"How much will be Nokia's share buyback?\"\n",
        "# query = \"What were the reasons for Nokia shares increase on Thursday?\"\n",
        "\n",
        "# Unsuccessful querys\n",
        "# query = \"What was Nokia shares price increase on Thursday?\"\n",
        "# query = \"Can you infer from all the documents what the reason for Nokia's year-on-year decline in net sales and operating profit was in 2023?\"\n",
        "\n",
        "query = \"How much was the share buyback in dollars?\"\n",
        "\n",
        "# Query the collection to get the 2 most relevant results\n",
        "results = nokia_collection.query(query_texts=[query], n_results=1, include=[\"documents\", \"metadatas\"])\n",
        "\n",
        "\n",
        "# Get the response from Gemini\n",
        "response = get_gemini_response(query, results[\"documents\"][0])\n",
        "\n",
        "# Output, with sources\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "awzVHabHxUZm",
        "outputId": "3f167b32-4c54-4790-e540-921c0f4dc547"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "653 million\n"
          ]
        }
      ]
    }
  ]
}