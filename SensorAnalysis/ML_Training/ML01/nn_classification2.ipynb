{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"elapsed":6496,"status":"ok","timestamp":1705414457751,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"naqgmGruWck9","outputId":"940c23a2-75af-4c0e-af63-cc9295e82c1b"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.stats import linregress\n","from matplotlib.colors import ListedColormap\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["#------------------------ Load and preprocess the data ------------------------\n","df = pd.read_csv('postgres_new_data.csv')\n","\n","# Generate the column names as rv1, rv2, ..., rv1500\n","col_names = [f'rv{i}' for i in range(1, 1501)]\n","\n","# Split the rv column by comma into a list of Series\n","split_series = df['rv'].str.split(',', n=1499, expand=True).apply(pd.Series)\n","\n","# Concatenate the original DataFrame with the split Series\n","df = pd.concat([df, split_series], axis=1)\n","\n","# Rename the split columns\n","df.rename(columns=dict(zip(split_series.columns, col_names)), inplace=True)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['rv1', 'rv2', 'rv3', 'rv4', 'rv5', 'rv6', 'rv7', 'rv8', 'rv9', 'rv10', 'rv11', 'rv12', 'rv13', 'rv14', 'rv15', 'rv16', 'rv17', 'rv18', 'rv19', 'rv20', 'rv21', 'rv22', 'rv23', 'rv24', 'rv25', 'rv26', 'rv27', 'rv28', 'rv29', 'rv30', 'rv31', 'rv32', 'rv33', 'rv34', 'rv35', 'rv36', 'rv37', 'rv38', 'rv39', 'rv40', 'rv41', 'rv42', 'rv43', 'rv44', 'rv45', 'rv46', 'rv47', 'rv48', 'rv49', 'rv50', 'rv51', 'rv52', 'rv53', 'rv54', 'rv55', 'rv56', 'rv57', 'rv58', 'rv59', 'rv60', 'rv61', 'rv62', 'rv63', 'rv64', 'rv65', 'rv66', 'rv67', 'rv68', 'rv69', 'rv70', 'rv71', 'rv72', 'rv73', 'rv74', 'rv75', 'rv76', 'rv77', 'rv78', 'rv79', 'rv80', 'rv81', 'rv82', 'rv83', 'rv84', 'rv85', 'rv86', 'rv87', 'rv88', 'rv89', 'rv90', 'rv91', 'rv92', 'rv93', 'rv94', 'rv95', 'rv96', 'rv97', 'rv98', 'rv99', 'rv100', 'rv101', 'rv102', 'rv103', 'rv104', 'rv105', 'rv106', 'rv107', 'rv108', 'rv109', 'rv110', 'rv111', 'rv112', 'rv113', 'rv114', 'rv115', 'rv116', 'rv117', 'rv118', 'rv119', 'rv120', 'rv121', 'rv122', 'rv123', 'rv124', 'rv125', 'rv126', 'rv127', 'rv128', 'rv129', 'rv130', 'rv131', 'rv132', 'rv133', 'rv134', 'rv135', 'rv136', 'rv137', 'rv138', 'rv139', 'rv140', 'rv141', 'rv142', 'rv143', 'rv144', 'rv145', 'rv146', 'rv147', 'rv148', 'rv149', 'rv150', 'rv151', 'rv152', 'rv153', 'rv154', 'rv155', 'rv156', 'rv157', 'rv158', 'rv159', 'rv160', 'rv161', 'rv162', 'rv163', 'rv164', 'rv165', 'rv166', 'rv167', 'rv168', 'rv169', 'rv170', 'rv171', 'rv172', 'rv173', 'rv174', 'rv175', 'rv176', 'rv177', 'rv178', 'rv179', 'rv180', 'rv181', 'rv182', 'rv183', 'rv184', 'rv185', 'rv186', 'rv187', 'rv188', 'rv189', 'rv190', 'rv191', 'rv192', 'rv193', 'rv194', 'rv195', 'rv196', 'rv197', 'rv198', 'rv199', 'rv200', 'rv201', 'rv202', 'rv203', 'rv204', 'rv205', 'rv206', 'rv207', 'rv208', 'rv209', 'rv210', 'rv211', 'rv212', 'rv213', 'rv214', 'rv215', 'rv216', 'rv217', 'rv218', 'rv219', 'rv220', 'rv221', 'rv222', 'rv223', 'rv224', 'rv225', 'rv226', 'rv227', 'rv228', 'rv229', 'rv230', 'rv231', 'rv232', 'rv233', 'rv234', 'rv235', 'rv236', 'rv237', 'rv238', 'rv239', 'rv240', 'rv241', 'rv242', 'rv243', 'rv244', 'rv245', 'rv246', 'rv247', 'rv248', 'rv249', 'rv250', 'rv251', 'rv252', 'rv253', 'rv254', 'rv255', 'rv256', 'rv257', 'rv258', 'rv259', 'rv260', 'rv261', 'rv262', 'rv263', 'rv264', 'rv265', 'rv266', 'rv267', 'rv268', 'rv269', 'rv270', 'rv271', 'rv272', 'rv273', 'rv274', 'rv275', 'rv276', 'rv277', 'rv278', 'rv279', 'rv280', 'rv281', 'rv282', 'rv283', 'rv284', 'rv285', 'rv286', 'rv287', 'rv288', 'rv289', 'rv290', 'rv291', 'rv292', 'rv293', 'rv294', 'rv295', 'rv296', 'rv297', 'rv298', 'rv299', 'rv300', 'rv301', 'rv302', 'rv303', 'rv304', 'rv305', 'rv306', 'rv307', 'rv308', 'rv309', 'rv310', 'rv311', 'rv312', 'rv313', 'rv314', 'rv315', 'rv316', 'rv317', 'rv318', 'rv319', 'rv320', 'rv321', 'rv322', 'rv323', 'rv324', 'rv325', 'rv326', 'rv327', 'rv328', 'rv329', 'rv330', 'rv331', 'rv332', 'rv333', 'rv334', 'rv335', 'rv336', 'rv337', 'rv338', 'rv339', 'rv340', 'rv341', 'rv342', 'rv343', 'rv344', 'rv345', 'rv346', 'rv347', 'rv348', 'rv349', 'rv350', 'rv351', 'rv352', 'rv353', 'rv354', 'rv355', 'rv356', 'rv357', 'rv358', 'rv359', 'rv360', 'rv361', 'rv362', 'rv363', 'rv364', 'rv365', 'rv366', 'rv367', 'rv368', 'rv369', 'rv370', 'rv371', 'rv372', 'rv373', 'rv374', 'rv375', 'rv376', 'rv377', 'rv378', 'rv379', 'rv380', 'rv381', 'rv382', 'rv383', 'rv384', 'rv385', 'rv386', 'rv387', 'rv388', 'rv389', 'rv390', 'rv391', 'rv392', 'rv393', 'rv394', 'rv395', 'rv396', 'rv397', 'rv398', 'rv399', 'rv400', 'rv401', 'rv402', 'rv403', 'rv404', 'rv405', 'rv406', 'rv407', 'rv408', 'rv409', 'rv410', 'rv411', 'rv412', 'rv413', 'rv414', 'rv415', 'rv416', 'rv417', 'rv418', 'rv419', 'rv420', 'rv421', 'rv422', 'rv423', 'rv424', 'rv425', 'rv426', 'rv427', 'rv428', 'rv429', 'rv430', 'rv431', 'rv432', 'rv433', 'rv434', 'rv435', 'rv436', 'rv437', 'rv438', 'rv439', 'rv440', 'rv441', 'rv442', 'rv443', 'rv444', 'rv445', 'rv446', 'rv447', 'rv448', 'rv449', 'rv450', 'rv451', 'rv452', 'rv453', 'rv454', 'rv455', 'rv456', 'rv457', 'rv458', 'rv459', 'rv460', 'rv461', 'rv462', 'rv463', 'rv464', 'rv465', 'rv466', 'rv467', 'rv468', 'rv469', 'rv470', 'rv471', 'rv472', 'rv473', 'rv474', 'rv475', 'rv476', 'rv477', 'rv478', 'rv479', 'rv480', 'rv481', 'rv482', 'rv483', 'rv484', 'rv485', 'rv486', 'rv487', 'rv488', 'rv489', 'rv490', 'rv491', 'rv492', 'rv493', 'rv494', 'rv495', 'rv496', 'rv497', 'rv498', 'rv499', 'rv500', 'rv501', 'rv502', 'rv503', 'rv504', 'rv505', 'rv506', 'rv507', 'rv508', 'rv509', 'rv510', 'rv511', 'rv512', 'rv513', 'rv514', 'rv515', 'rv516', 'rv517', 'rv518', 'rv519', 'rv520', 'rv521', 'rv522', 'rv523', 'rv524', 'rv525', 'rv526', 'rv527', 'rv528', 'rv529', 'rv530', 'rv531', 'rv532', 'rv533', 'rv534', 'rv535', 'rv536', 'rv537', 'rv538', 'rv539', 'rv540', 'rv541', 'rv542', 'rv543', 'rv544', 'rv545', 'rv546', 'rv547', 'rv548', 'rv549', 'rv550', 'rv551', 'rv552', 'rv553', 'rv554', 'rv555', 'rv556', 'rv557', 'rv558', 'rv559', 'rv560', 'rv561', 'rv562', 'rv563', 'rv564', 'rv565', 'rv566', 'rv567', 'rv568', 'rv569', 'rv570', 'rv571', 'rv572', 'rv573', 'rv574', 'rv575', 'rv576', 'rv577', 'rv578', 'rv579', 'rv580', 'rv581', 'rv582', 'rv583', 'rv584', 'rv585', 'rv586', 'rv587', 'rv588', 'rv589', 'rv590', 'rv591', 'rv592', 'rv593', 'rv594', 'rv595', 'rv596', 'rv597', 'rv598', 'rv599', 'rv600', 'rv601', 'rv602', 'rv603', 'rv604', 'rv605', 'rv606', 'rv607', 'rv608', 'rv609', 'rv610', 'rv611', 'rv612', 'rv613', 'rv614', 'rv615', 'rv616', 'rv617', 'rv618', 'rv619', 'rv620', 'rv621', 'rv622', 'rv623', 'rv624', 'rv625', 'rv626', 'rv627', 'rv628', 'rv629', 'rv630', 'rv631', 'rv632', 'rv633', 'rv634', 'rv635', 'rv636', 'rv637', 'rv638', 'rv639', 'rv640', 'rv641', 'rv642', 'rv643', 'rv644', 'rv645', 'rv646', 'rv647', 'rv648', 'rv649', 'rv650', 'rv651', 'rv652', 'rv653', 'rv654', 'rv655', 'rv656', 'rv657', 'rv658', 'rv659', 'rv660', 'rv661', 'rv662', 'rv663', 'rv664', 'rv665', 'rv666', 'rv667', 'rv668', 'rv669', 'rv670', 'rv671', 'rv672', 'rv673', 'rv674', 'rv675', 'rv676', 'rv677', 'rv678', 'rv679', 'rv680', 'rv681', 'rv682', 'rv683', 'rv684', 'rv685', 'rv686', 'rv687', 'rv688', 'rv689', 'rv690', 'rv691', 'rv692', 'rv693', 'rv694', 'rv695', 'rv696', 'rv697', 'rv698', 'rv699', 'rv700', 'rv701', 'rv702', 'rv703', 'rv704', 'rv705', 'rv706', 'rv707', 'rv708', 'rv709', 'rv710', 'rv711', 'rv712', 'rv713', 'rv714', 'rv715', 'rv716', 'rv717', 'rv718', 'rv719', 'rv720', 'rv721', 'rv722', 'rv723', 'rv724', 'rv725', 'rv726', 'rv727', 'rv728', 'rv729', 'rv730', 'rv731', 'rv732', 'rv733', 'rv734', 'rv735', 'rv736', 'rv737', 'rv738', 'rv739', 'rv740', 'rv741', 'rv742', 'rv743', 'rv744', 'rv745', 'rv746', 'rv747', 'rv748', 'rv749', 'rv750', 'rv751', 'rv752', 'rv753', 'rv754', 'rv755', 'rv756', 'rv757', 'rv758', 'rv759', 'rv760', 'rv761', 'rv762', 'rv763', 'rv764', 'rv765', 'rv766', 'rv767', 'rv768', 'rv769', 'rv770', 'rv771', 'rv772', 'rv773', 'rv774', 'rv775', 'rv776', 'rv777', 'rv778', 'rv779', 'rv780', 'rv781', 'rv782', 'rv783', 'rv784', 'rv785', 'rv786', 'rv787', 'rv788', 'rv789', 'rv790', 'rv791', 'rv792', 'rv793', 'rv794', 'rv795', 'rv796', 'rv797', 'rv798', 'rv799', 'rv800', 'rv801', 'rv802', 'rv803', 'rv804', 'rv805', 'rv806', 'rv807', 'rv808', 'rv809', 'rv810', 'rv811', 'rv812', 'rv813', 'rv814', 'rv815', 'rv816', 'rv817', 'rv818', 'rv819', 'rv820', 'rv821', 'rv822', 'rv823', 'rv824', 'rv825', 'rv826', 'rv827', 'rv828', 'rv829', 'rv830', 'rv831', 'rv832', 'rv833', 'rv834', 'rv835', 'rv836', 'rv837', 'rv838', 'rv839', 'rv840', 'rv841', 'rv842', 'rv843', 'rv844', 'rv845', 'rv846', 'rv847', 'rv848', 'rv849', 'rv850', 'rv851', 'rv852', 'rv853', 'rv854', 'rv855', 'rv856', 'rv857', 'rv858', 'rv859', 'rv860', 'rv861', 'rv862', 'rv863', 'rv864', 'rv865', 'rv866', 'rv867', 'rv868', 'rv869', 'rv870', 'rv871', 'rv872', 'rv873', 'rv874', 'rv875', 'rv876', 'rv877', 'rv878', 'rv879', 'rv880', 'rv881', 'rv882', 'rv883', 'rv884', 'rv885', 'rv886', 'rv887', 'rv888', 'rv889', 'rv890', 'rv891', 'rv892', 'rv893', 'rv894', 'rv895', 'rv896', 'rv897', 'rv898', 'rv899', 'rv900', 'rv901', 'rv902', 'rv903', 'rv904', 'rv905', 'rv906', 'rv907', 'rv908', 'rv909', 'rv910', 'rv911', 'rv912', 'rv913', 'rv914', 'rv915', 'rv916', 'rv917', 'rv918', 'rv919', 'rv920', 'rv921', 'rv922', 'rv923', 'rv924', 'rv925', 'rv926', 'rv927', 'rv928', 'rv929', 'rv930', 'rv931', 'rv932', 'rv933', 'rv934', 'rv935', 'rv936', 'rv937', 'rv938', 'rv939', 'rv940', 'rv941', 'rv942', 'rv943', 'rv944', 'rv945', 'rv946', 'rv947', 'rv948', 'rv949', 'rv950', 'rv951', 'rv952', 'rv953', 'rv954', 'rv955', 'rv956', 'rv957', 'rv958', 'rv959', 'rv960', 'rv961', 'rv962', 'rv963', 'rv964', 'rv965', 'rv966', 'rv967', 'rv968', 'rv969', 'rv970', 'rv971', 'rv972', 'rv973', 'rv974', 'rv975', 'rv976', 'rv977', 'rv978', 'rv979', 'rv980', 'rv981', 'rv982', 'rv983', 'rv984', 'rv985', 'rv986', 'rv987', 'rv988', 'rv989', 'rv990', 'rv991', 'rv992', 'rv993', 'rv994', 'rv995', 'rv996', 'rv997', 'rv998', 'rv999', 'rv1000', 'rv1001', 'rv1002', 'rv1003', 'rv1004', 'rv1005', 'rv1006', 'rv1007', 'rv1008', 'rv1009', 'rv1010', 'rv1011', 'rv1012', 'rv1013', 'rv1014', 'rv1015', 'rv1016', 'rv1017', 'rv1018', 'rv1019', 'rv1020', 'rv1021', 'rv1022', 'rv1023', 'rv1024', 'rv1025', 'rv1026', 'rv1027', 'rv1028', 'rv1029', 'rv1030', 'rv1031', 'rv1032', 'rv1033', 'rv1034', 'rv1035', 'rv1036', 'rv1037', 'rv1038', 'rv1039', 'rv1040', 'rv1041', 'rv1042', 'rv1043', 'rv1044', 'rv1045', 'rv1046', 'rv1047', 'rv1048', 'rv1049', 'rv1050', 'rv1051', 'rv1052', 'rv1053', 'rv1054', 'rv1055', 'rv1056', 'rv1057', 'rv1058', 'rv1059', 'rv1060', 'rv1061', 'rv1062', 'rv1063', 'rv1064', 'rv1065', 'rv1066', 'rv1067', 'rv1068', 'rv1069', 'rv1070', 'rv1071', 'rv1072', 'rv1073', 'rv1074', 'rv1075', 'rv1076', 'rv1077', 'rv1078', 'rv1079', 'rv1080', 'rv1081', 'rv1082', 'rv1083', 'rv1084', 'rv1085', 'rv1086', 'rv1087', 'rv1088', 'rv1089', 'rv1090', 'rv1091', 'rv1092', 'rv1093', 'rv1094', 'rv1095', 'rv1096', 'rv1097', 'rv1098', 'rv1099', 'rv1100', 'rv1101', 'rv1102', 'rv1103', 'rv1104', 'rv1105', 'rv1106', 'rv1107', 'rv1108', 'rv1109', 'rv1110', 'rv1111', 'rv1112', 'rv1113', 'rv1114', 'rv1115', 'rv1116', 'rv1117', 'rv1118', 'rv1119', 'rv1120', 'rv1121', 'rv1122', 'rv1123', 'rv1124', 'rv1125', 'rv1126', 'rv1127', 'rv1128', 'rv1129', 'rv1130', 'rv1131', 'rv1132', 'rv1133', 'rv1134', 'rv1135', 'rv1136', 'rv1137', 'rv1138', 'rv1139', 'rv1140', 'rv1141', 'rv1142', 'rv1143', 'rv1144', 'rv1145', 'rv1146', 'rv1147', 'rv1148', 'rv1149', 'rv1150', 'rv1151', 'rv1152', 'rv1153', 'rv1154', 'rv1155', 'rv1156', 'rv1157', 'rv1158', 'rv1159', 'rv1160', 'rv1161', 'rv1162', 'rv1163', 'rv1164', 'rv1165', 'rv1166', 'rv1167', 'rv1168', 'rv1169', 'rv1170', 'rv1171', 'rv1172', 'rv1173', 'rv1174', 'rv1175', 'rv1176', 'rv1177', 'rv1178', 'rv1179', 'rv1180', 'rv1181', 'rv1182', 'rv1183', 'rv1184', 'rv1185', 'rv1186', 'rv1187', 'rv1188', 'rv1189', 'rv1190', 'rv1191', 'rv1192', 'rv1193', 'rv1194', 'rv1195', 'rv1196', 'rv1197', 'rv1198', 'rv1199', 'rv1200', 'rv1201', 'rv1202', 'rv1203', 'rv1204', 'rv1205', 'rv1206', 'rv1207', 'rv1208', 'rv1209', 'rv1210', 'rv1211', 'rv1212', 'rv1213', 'rv1214', 'rv1215', 'rv1216', 'rv1217', 'rv1218', 'rv1219', 'rv1220', 'rv1221', 'rv1222', 'rv1223', 'rv1224', 'rv1225', 'rv1226', 'rv1227', 'rv1228', 'rv1229', 'rv1230', 'rv1231', 'rv1232', 'rv1233', 'rv1234', 'rv1235', 'rv1236', 'rv1237', 'rv1238', 'rv1239', 'rv1240', 'rv1241', 'rv1242', 'rv1243', 'rv1244', 'rv1245', 'rv1246', 'rv1247', 'rv1248', 'rv1249', 'rv1250', 'rv1251', 'rv1252', 'rv1253', 'rv1254', 'rv1255', 'rv1256', 'rv1257', 'rv1258', 'rv1259', 'rv1260', 'rv1261', 'rv1262', 'rv1263', 'rv1264', 'rv1265', 'rv1266', 'rv1267', 'rv1268', 'rv1269', 'rv1270', 'rv1271', 'rv1272', 'rv1273', 'rv1274', 'rv1275', 'rv1276', 'rv1277', 'rv1278', 'rv1279', 'rv1280', 'rv1281', 'rv1282', 'rv1283', 'rv1284', 'rv1285', 'rv1286', 'rv1287', 'rv1288', 'rv1289', 'rv1290', 'rv1291', 'rv1292', 'rv1293', 'rv1294', 'rv1295', 'rv1296', 'rv1297', 'rv1298', 'rv1299', 'rv1300', 'rv1301', 'rv1302', 'rv1303', 'rv1304', 'rv1305', 'rv1306', 'rv1307', 'rv1308', 'rv1309', 'rv1310', 'rv1311', 'rv1312', 'rv1313', 'rv1314', 'rv1315', 'rv1316', 'rv1317', 'rv1318', 'rv1319', 'rv1320', 'rv1321', 'rv1322', 'rv1323', 'rv1324', 'rv1325', 'rv1326', 'rv1327', 'rv1328', 'rv1329', 'rv1330', 'rv1331', 'rv1332', 'rv1333', 'rv1334', 'rv1335', 'rv1336', 'rv1337', 'rv1338', 'rv1339', 'rv1340', 'rv1341', 'rv1342', 'rv1343', 'rv1344', 'rv1345', 'rv1346', 'rv1347', 'rv1348', 'rv1349', 'rv1350', 'rv1351', 'rv1352', 'rv1353', 'rv1354', 'rv1355', 'rv1356', 'rv1357', 'rv1358', 'rv1359', 'rv1360', 'rv1361', 'rv1362', 'rv1363', 'rv1364', 'rv1365', 'rv1366', 'rv1367', 'rv1368', 'rv1369', 'rv1370', 'rv1371', 'rv1372', 'rv1373', 'rv1374', 'rv1375', 'rv1376', 'rv1377', 'rv1378', 'rv1379', 'rv1380', 'rv1381', 'rv1382', 'rv1383', 'rv1384', 'rv1385', 'rv1386', 'rv1387', 'rv1388', 'rv1389', 'rv1390', 'rv1391', 'rv1392', 'rv1393', 'rv1394', 'rv1395', 'rv1396', 'rv1397', 'rv1398', 'rv1399', 'rv1400', 'rv1401', 'rv1402', 'rv1403', 'rv1404', 'rv1405', 'rv1406', 'rv1407', 'rv1408', 'rv1409', 'rv1410', 'rv1411', 'rv1412', 'rv1413', 'rv1414', 'rv1415', 'rv1416', 'rv1417', 'rv1418', 'rv1419', 'rv1420', 'rv1421', 'rv1422', 'rv1423', 'rv1424', 'rv1425', 'rv1426', 'rv1427', 'rv1428', 'rv1429', 'rv1430', 'rv1431', 'rv1432', 'rv1433', 'rv1434', 'rv1435', 'rv1436', 'rv1437', 'rv1438', 'rv1439', 'rv1440', 'rv1441', 'rv1442', 'rv1443', 'rv1444', 'rv1445', 'rv1446', 'rv1447', 'rv1448', 'rv1449', 'rv1450', 'rv1451', 'rv1452', 'rv1453', 'rv1454', 'rv1455', 'rv1456', 'rv1457', 'rv1458', 'rv1459', 'rv1460', 'rv1461', 'rv1462', 'rv1463', 'rv1464', 'rv1465', 'rv1466', 'rv1467', 'rv1468', 'rv1469', 'rv1470', 'rv1471', 'rv1472', 'rv1473', 'rv1474', 'rv1475', 'rv1476', 'rv1477', 'rv1478', 'rv1479', 'rv1480', 'rv1481', 'rv1482', 'rv1483', 'rv1484', 'rv1485', 'rv1486', 'rv1487', 'rv1488', 'rv1489', 'rv1490', 'rv1491', 'rv1492', 'rv1493', 'rv1494', 'rv1495', 'rv1496', 'rv1497', 'rv1498', 'rv1499', 'rv1500']\n","          rv1       rv2       rv3       rv4       rv5       rv6       rv7  \\\n","0     26.0026   25.0025   26.0026   26.0026   26.0026   26.0026   26.0026   \n","1     25.0025   25.0025   25.0025   25.0025   25.0025   25.0025   25.0025   \n","2     25.0025   25.0025   25.0025   25.0025   25.0025   25.0025   25.0025   \n","3     28.0028   28.0028   28.0028   28.0028   28.0028   28.0028   28.0028   \n","4     27.0027   28.0028   28.0028   28.0028   27.0027   28.0028   28.0028   \n","...       ...       ...       ...       ...       ...       ...       ...   \n","5379  27.0027   26.0026   26.0026   27.0027   27.0027   27.0027   27.0027   \n","5380  27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   \n","5381  27.0027   27.0027   26.0026   27.0027   27.0027   27.0027   27.0027   \n","5382  27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   \n","5383  27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   \n","\n","           rv8       rv9      rv10  ...    rv1491    rv1492    rv1493  \\\n","0      26.0026   25.0025   26.0026  ...   26.0026   26.0026   25.0025   \n","1      25.0025   25.0025   25.0025  ...   24.0024   25.0025   24.0024   \n","2      25.0025   25.0025   25.0025  ...   25.0025   25.0025   25.0025   \n","3      28.0028   28.0028   28.0028  ...   28.0028   28.0028   28.0028   \n","4      29.0029   28.0028   28.0028  ...   28.0028   28.0028   28.0028   \n","...        ...       ...       ...  ...       ...       ...       ...   \n","5379   27.0027   27.0027   27.0027  ...   26.0026   27.0027   27.0027   \n","5380   27.0027   27.0027   27.0027  ...   27.0027   26.0026   26.0026   \n","5381   27.0027   26.0026   27.0027  ...   27.0027   27.0027   27.0027   \n","5382   26.0026   26.0026   27.0027  ...   26.0026   26.0026   26.0026   \n","5383   27.0027   27.0027   27.0027  ...   27.0027   27.0027   27.0027   \n","\n","        rv1494    rv1495    rv1496    rv1497    rv1498    rv1499    rv1500  \n","0      26.0026   26.0026   26.0026   26.0026   25.0025   26.0026   26.0026  \n","1      25.0025   25.0025   25.0025   25.0025   25.0025   25.0025   25.0025  \n","2      25.0025   25.0025   25.0025   25.0025   25.0025   25.0025   25.0025  \n","3      28.0028   28.0028   28.0028   28.0028   28.0028   28.0028   28.0028  \n","4      28.0028   28.0028   28.0028   28.0028   28.0028   28.0028   28.0028  \n","...        ...       ...       ...       ...       ...       ...       ...  \n","5379   27.0027   26.0026   27.0027   27.0027   27.0027   27.0027   26.0026  \n","5380   27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   27.0027  \n","5381   27.0027   27.0027   27.0027   27.0027   26.0026   27.0027   27.0027  \n","5382   26.0026   27.0027   27.0027   26.0026   26.0026   26.0026   27.0027  \n","5383   26.0026   27.0027   26.0026   26.0026   27.0027   26.0026   27.0027  \n","\n","[5384 rows x 1500 columns]\n"]}],"source":["#column_names = df.columns.tolist()\n","# Columns to remove\n","#columns_to_remove = ['tm','knt','ae','ae_cl','rv']\n","#numeric_columns = list(set(column_names).difference(columns_to_remove))\n","#numeric_columns = list(filter(lambda col: col not in columns_to_remove, column_names))\n","\n","\n","numeric_columns = [f'rv{i}' for i in range(1, 1501)]\n","\n","# Print the generated variable names\n","print(numeric_columns)\n","\n","\n","print(df[numeric_columns])"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["\n","model = LinearRegression()\n","def get_coeff(row, model=model):\n","    # Select only relevant columns\n","    row = row.loc[numeric_columns]\n","    # Drop NaN values\n","    row = row.dropna()\n","    if len(row) > 1:  # Check if there are enough data points for regression\n","        X = np.arange(len(row)).reshape(-1, 1)\n","        y = row.values.reshape(-1, 1)\n","        model.fit(X, y)\n","        slope = model.coef_[0][0]\n","        return slope\n","    else:\n","        return np.nan  # Return "]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["          rv1       rv2       rv3       rv4       rv5       rv6       rv7  \\\n","0     26.0026   25.0025   26.0026   26.0026   26.0026   26.0026   26.0026   \n","1     25.0025   25.0025   25.0025   25.0025   25.0025   25.0025   25.0025   \n","2     25.0025   25.0025   25.0025   25.0025   25.0025   25.0025   25.0025   \n","3     28.0028   28.0028   28.0028   28.0028   28.0028   28.0028   28.0028   \n","4     27.0027   28.0028   28.0028   28.0028   27.0027   28.0028   28.0028   \n","...       ...       ...       ...       ...       ...       ...       ...   \n","5379  27.0027   26.0026   26.0026   27.0027   27.0027   27.0027   27.0027   \n","5380  27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   \n","5381  27.0027   27.0027   26.0026   27.0027   27.0027   27.0027   27.0027   \n","5382  27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   \n","5383  27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   \n","\n","           rv8       rv9      rv10  ...    rv1491    rv1492    rv1493  \\\n","0      26.0026   25.0025   26.0026  ...   26.0026   26.0026   25.0025   \n","1      25.0025   25.0025   25.0025  ...   24.0024   25.0025   24.0024   \n","2      25.0025   25.0025   25.0025  ...   25.0025   25.0025   25.0025   \n","3      28.0028   28.0028   28.0028  ...   28.0028   28.0028   28.0028   \n","4      29.0029   28.0028   28.0028  ...   28.0028   28.0028   28.0028   \n","...        ...       ...       ...  ...       ...       ...       ...   \n","5379   27.0027   27.0027   27.0027  ...   26.0026   27.0027   27.0027   \n","5380   27.0027   27.0027   27.0027  ...   27.0027   26.0026   26.0026   \n","5381   27.0027   26.0026   27.0027  ...   27.0027   27.0027   27.0027   \n","5382   26.0026   26.0026   27.0027  ...   26.0026   26.0026   26.0026   \n","5383   27.0027   27.0027   27.0027  ...   27.0027   27.0027   27.0027   \n","\n","        rv1494    rv1495    rv1496    rv1497    rv1498    rv1499    rv1500  \n","0      26.0026   26.0026   26.0026   26.0026   25.0025   26.0026   26.0026  \n","1      25.0025   25.0025   25.0025   25.0025   25.0025   25.0025   25.0025  \n","2      25.0025   25.0025   25.0025   25.0025   25.0025   25.0025   25.0025  \n","3      28.0028   28.0028   28.0028   28.0028   28.0028   28.0028   28.0028  \n","4      28.0028   28.0028   28.0028   28.0028   28.0028   28.0028   28.0028  \n","...        ...       ...       ...       ...       ...       ...       ...  \n","5379   27.0027   26.0026   27.0027   27.0027   27.0027   27.0027   26.0026  \n","5380   27.0027   27.0027   27.0027   27.0027   27.0027   27.0027   27.0027  \n","5381   27.0027   27.0027   27.0027   27.0027   26.0026   27.0027   27.0027  \n","5382   26.0026   27.0027   27.0027   26.0026   26.0026   26.0026   27.0027  \n","5383   26.0026   27.0027   26.0026   26.0026   27.0027   26.0026   27.0027  \n","\n","[5384 rows x 1500 columns]\n"]}],"source":["print(df[numeric_columns])"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tm</th>\n","      <th>knt</th>\n","      <th>ae</th>\n","      <th>ae_cl</th>\n","      <th>rv</th>\n","      <th>rv1</th>\n","      <th>rv2</th>\n","      <th>rv3</th>\n","      <th>rv4</th>\n","      <th>rv5</th>\n","      <th>...</th>\n","      <th>rv1493</th>\n","      <th>rv1494</th>\n","      <th>rv1495</th>\n","      <th>rv1496</th>\n","      <th>rv1497</th>\n","      <th>rv1498</th>\n","      <th>rv1499</th>\n","      <th>rv1500</th>\n","      <th>mn</th>\n","      <th>ds</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-10-13 03:38:11.838465</td>\n","      <td>1500</td>\n","      <td>0.109208</td>\n","      <td>0</td>\n","      <td>26.0026, 25.0025, 26.0026, 26.0026, 26.0026, 2...</td>\n","      <td>26.0026</td>\n","      <td>25.0025</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>...</td>\n","      <td>25.0025</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>25.0025</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2022-10-13 13:30:49.852566</td>\n","      <td>1500</td>\n","      <td>0.317388</td>\n","      <td>0</td>\n","      <td>25.0025, 25.0025, 25.0025, 25.0025, 25.0025, 2...</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>...</td>\n","      <td>24.0024</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2022-10-13 14:17:07.820202</td>\n","      <td>1500</td>\n","      <td>0.300354</td>\n","      <td>0</td>\n","      <td>25.0025, 25.0025, 25.0025, 25.0025, 25.0025, 2...</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>...</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022-09-07 23:13:37.665544</td>\n","      <td>1500</td>\n","      <td>0.179053</td>\n","      <td>0</td>\n","      <td>28.0028, 28.0028, 28.0028, 28.0028, 28.0028, 2...</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>...</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2022-09-07 23:25:58.593231</td>\n","      <td>1500</td>\n","      <td>0.300354</td>\n","      <td>0</td>\n","      <td>27.0027, 28.0028, 28.0028, 28.0028, 27.0027, 2...</td>\n","      <td>27.0027</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>27.0027</td>\n","      <td>...</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1507 columns</p>\n","</div>"],"text/plain":["                           tm   knt        ae  ae_cl  \\\n","0  2022-10-13 03:38:11.838465  1500  0.109208      0   \n","1  2022-10-13 13:30:49.852566  1500  0.317388      0   \n","2  2022-10-13 14:17:07.820202  1500  0.300354      0   \n","3  2022-09-07 23:13:37.665544  1500  0.179053      0   \n","4  2022-09-07 23:25:58.593231  1500  0.300354      0   \n","\n","                                                  rv      rv1       rv2  \\\n","0  26.0026, 25.0025, 26.0026, 26.0026, 26.0026, 2...  26.0026   25.0025   \n","1  25.0025, 25.0025, 25.0025, 25.0025, 25.0025, 2...  25.0025   25.0025   \n","2  25.0025, 25.0025, 25.0025, 25.0025, 25.0025, 2...  25.0025   25.0025   \n","3  28.0028, 28.0028, 28.0028, 28.0028, 28.0028, 2...  28.0028   28.0028   \n","4  27.0027, 28.0028, 28.0028, 28.0028, 27.0027, 2...  27.0027   28.0028   \n","\n","        rv3       rv4       rv5  ...    rv1493    rv1494    rv1495    rv1496  \\\n","0   26.0026   26.0026   26.0026  ...   25.0025   26.0026   26.0026   26.0026   \n","1   25.0025   25.0025   25.0025  ...   24.0024   25.0025   25.0025   25.0025   \n","2   25.0025   25.0025   25.0025  ...   25.0025   25.0025   25.0025   25.0025   \n","3   28.0028   28.0028   28.0028  ...   28.0028   28.0028   28.0028   28.0028   \n","4   28.0028   28.0028   27.0027  ...   28.0028   28.0028   28.0028   28.0028   \n","\n","     rv1497    rv1498    rv1499    rv1500  mn  ds  \n","0   26.0026   25.0025   26.0026   26.0026 NaN NaN  \n","1   25.0025   25.0025   25.0025   25.0025 NaN NaN  \n","2   25.0025   25.0025   25.0025   25.0025 NaN NaN  \n","3   28.0028   28.0028   28.0028   28.0028 NaN NaN  \n","4   28.0028   28.0028   28.0028   28.0028 NaN NaN  \n","\n","[5 rows x 1507 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["\n","df['mn'] = df[numeric_columns].select_dtypes(include='number').mean(axis=1)\n","df['ds'] = df[numeric_columns].select_dtypes(include='number').std(axis=1)\n","df.head()\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tm</th>\n","      <th>knt</th>\n","      <th>ae</th>\n","      <th>ae_cl</th>\n","      <th>rv1</th>\n","      <th>rv2</th>\n","      <th>rv3</th>\n","      <th>rv4</th>\n","      <th>rv5</th>\n","      <th>rv6</th>\n","      <th>...</th>\n","      <th>rv1494</th>\n","      <th>rv1495</th>\n","      <th>rv1496</th>\n","      <th>rv1497</th>\n","      <th>rv1498</th>\n","      <th>rv1499</th>\n","      <th>rv1500</th>\n","      <th>mn</th>\n","      <th>ds</th>\n","      <th>slope</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-10-13 03:38:11.838465</td>\n","      <td>1500</td>\n","      <td>0.109208</td>\n","      <td>0</td>\n","      <td>26.0026</td>\n","      <td>25.0025</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>...</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>25.0025</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-0.000023</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2022-10-13 13:30:49.852566</td>\n","      <td>1500</td>\n","      <td>0.317388</td>\n","      <td>0</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>...</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-0.000047</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2022-10-13 14:17:07.820202</td>\n","      <td>1500</td>\n","      <td>0.300354</td>\n","      <td>0</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>...</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-0.000024</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022-09-07 23:13:37.665544</td>\n","      <td>1500</td>\n","      <td>0.179053</td>\n","      <td>0</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>...</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.000035</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2022-09-07 23:25:58.593231</td>\n","      <td>1500</td>\n","      <td>0.300354</td>\n","      <td>0</td>\n","      <td>27.0027</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>27.0027</td>\n","      <td>28.0028</td>\n","      <td>...</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.000014</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1507 columns</p>\n","</div>"],"text/plain":["                           tm   knt        ae  ae_cl      rv1       rv2  \\\n","0  2022-10-13 03:38:11.838465  1500  0.109208      0  26.0026   25.0025   \n","1  2022-10-13 13:30:49.852566  1500  0.317388      0  25.0025   25.0025   \n","2  2022-10-13 14:17:07.820202  1500  0.300354      0  25.0025   25.0025   \n","3  2022-09-07 23:13:37.665544  1500  0.179053      0  28.0028   28.0028   \n","4  2022-09-07 23:25:58.593231  1500  0.300354      0  27.0027   28.0028   \n","\n","        rv3       rv4       rv5       rv6  ...    rv1494    rv1495    rv1496  \\\n","0   26.0026   26.0026   26.0026   26.0026  ...   26.0026   26.0026   26.0026   \n","1   25.0025   25.0025   25.0025   25.0025  ...   25.0025   25.0025   25.0025   \n","2   25.0025   25.0025   25.0025   25.0025  ...   25.0025   25.0025   25.0025   \n","3   28.0028   28.0028   28.0028   28.0028  ...   28.0028   28.0028   28.0028   \n","4   28.0028   28.0028   27.0027   28.0028  ...   28.0028   28.0028   28.0028   \n","\n","     rv1497    rv1498    rv1499    rv1500  mn  ds     slope  \n","0   26.0026   25.0025   26.0026   26.0026 NaN NaN -0.000023  \n","1   25.0025   25.0025   25.0025   25.0025 NaN NaN -0.000047  \n","2   25.0025   25.0025   25.0025   25.0025 NaN NaN -0.000024  \n","3   28.0028   28.0028   28.0028   28.0028 NaN NaN  0.000035  \n","4   28.0028   28.0028   28.0028   28.0028 NaN NaN  0.000014  \n","\n","[5 rows x 1507 columns]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["\n","df[\"slope\"] = df.apply(get_coeff, axis=1)\n","# Drop the original 'rv' column\n","df.drop('rv', axis=1, inplace=True)\n","df.head()"]},{"cell_type":"code","execution_count":133,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1705414457752,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"wzuf8zS4fys4","outputId":"c65c07a4-d509-46bb-ffd3-aac9b771ce63"},"outputs":[{"ename":"KeyError","evalue":"'rv1'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","\u001b[1;31mKeyError\u001b[0m: 'rv1'","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[1;32mIn [133], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#------------------------ Define the features and labels ------------------------\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrv1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrv1500\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# X = df[col_names].astype(float).values\u001b[39;00m\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mae_cl\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1066\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexing.py:1256\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    922\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 924\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexing.py:1290\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_slice_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getbool_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexing.py:1324\u001b[0m, in \u001b[0;36m_LocIndexer._get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1323\u001b[0m labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1324\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39maxis)\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6559\u001b[0m, in \u001b[0;36mIndex.slice_indexer\u001b[1;34m(self, start, end, step, kind)\u001b[0m\n\u001b[0;32m   6516\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6517\u001b[0m \u001b[38;5;124;03mCompute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[0;32m   6518\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6555\u001b[0m \u001b[38;5;124;03mslice(1, 3, None)\u001b[39;00m\n\u001b[0;32m   6556\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deprecated_arg(kind, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice_indexer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 6559\u001b[0m start_slice, end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_locs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6561\u001b[0m \u001b[38;5;66;03m# return a slice\u001b[39;00m\n\u001b[0;32m   6562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(start_slice):\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6767\u001b[0m, in \u001b[0;36mIndex.slice_locs\u001b[1;34m(self, start, end, step, kind)\u001b[0m\n\u001b[0;32m   6765\u001b[0m start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   6766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 6767\u001b[0m     start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_slice_bound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_slice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   6769\u001b[0m     start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6686\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side, kind)\u001b[0m\n\u001b[0;32m   6683\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_searchsorted_monotonic(label, side)\n\u001b[0;32m   6684\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   6685\u001b[0m         \u001b[38;5;66;03m# raise the original KeyError\u001b[39;00m\n\u001b[1;32m-> 6686\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m   6688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(slc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   6689\u001b[0m     \u001b[38;5;66;03m# get_loc may return a boolean array, which\u001b[39;00m\n\u001b[0;32m   6690\u001b[0m     \u001b[38;5;66;03m# is OK as long as they are representable by a slice.\u001b[39;00m\n\u001b[0;32m   6691\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m is_bool_dtype(slc\u001b[38;5;241m.\u001b[39mdtype)\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6680\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side, kind)\u001b[0m\n\u001b[0;32m   6678\u001b[0m \u001b[38;5;66;03m# we need to look up the label\u001b[39;00m\n\u001b[0;32m   6679\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6680\u001b[0m     slc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   6682\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[1;31mKeyError\u001b[0m: 'rv1'"]}],"source":["#------------------------ Define the features and labels ------------------------\n","\n","\n","\n","X = df.loc[:, 'rv1':'rv1500'].astype(float).values\n","X = df.loc[:, ['rv1', 'rv2', 'mn', 'ds']].astype(float).values\n","\n","# X = df[col_names].astype(float).values\n","y = df['ae_cl']\n","\n","# Create a mask that is True for non-nan values and False for nan values\n","mask = ~np.isnan(y)\n","\n","# Apply the mask to both X and y\n","X = X[mask]\n","y = y[mask]\n","\n","# Check the count of each class in y\n","print(np.unique(y, return_counts=True))\n","\n","# Convert the data to tensors\n","X_tensor = torch.from_numpy(X)\n","y_tensor = torch.LongTensor(y)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# X = df[col_names].astype(float).values\n","y = df['ae_cl']\n","\n","# Create a mask that is True for non-nan values and False for nan values\n","mask = ~np.isnan(y)\n","\n","# Apply the mask to both X and y\n","X = X[mask]\n","y = y[mask]\n","\n","# Check the count of each class in y\n","print(np.unique(y, return_counts=True))\n"]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[],"source":["\n","# Convert the data to tensors\n","X_tensor = torch.from_numpy(X)\n","y_tensor = torch.LongTensor(y)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(array([0, 1, 2], dtype=int64), array([ 116,  268, 5000], dtype=int64))\n"]}],"source":["\n","# Apply the mask to both X and y\n","X = X[mask]\n","y = y[mask]\n","\n","# Check the count of each class in y\n","print(np.unique(y, return_counts=True))\n","\n","# Convert the data to tensors\n","X_tensor = torch.from_numpy(X)\n","y_tensor = torch.LongTensor(y)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.1, random_state=42)\n"]},{"cell_type":"code","execution_count":123,"metadata":{"executionInfo":{"elapsed":219,"status":"ok","timestamp":1705489688253,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"qdr65VXwh_La"},"outputs":[],"source":["#------------------------ Define the neural network model ------------------------\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.fc1 = nn.Linear(1500, 512)  # Input layer with 1500 input features and 1500 hidden units\n","        self.fc2 = nn.Linear(512, 3)  # Hidden layer with 1500 units and 3 output units\n","        #self.softmax = nn.LogSoftmax.Softmax(dim=1)  # Softmax layer to get probabilities of each class\n","        self.softmax = nn.LogSoftmax(dim=1)  # Softmax layer to get probabilities of each class\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))  # Apply ReLU activation to the hidden layer\n","        x = self.fc2(x)  # Apply linear transformation to the output layer\n","        x = self.softmax(x)  # Apply softmax to get probabilities of each class\n","        \n","        return x\n","\n","\n","# Create an instance of the neural network model\n","model = NeuralNetwork()\n","\n","# Cast X_train and X_test to the same data type as model.fc1.weight\n","X_train = X_train.to(model.fc1.weight.dtype)\n","X_test = X_test.to(model.fc1.weight.dtype)\n","\n","# Assigning more weight to minority classes\n","total = 116 + 268 + 5000 # Total number of samples\n","weight_0 = total / 116 # Weight for class 0\n","weight_1 = total / 268 # Weight for class 1\n","weight_2 = total / 5000 # Weight for class 2\n","weight = torch.tensor([weight_0, weight_1, weight_2]) # Tensor of class weights\n","\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss(weight=weight)\n","optimizer = optim.Adam(model.parameters(), lr=0.00001)\n"]},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[],"source":["\n","# Create an instance of the neural network model\n","model = NeuralNetwork()\n","\n","# Cast X_train and X_test to the same data type as model.fc1.weight\n","X_train = X_train.to(model.fc1.weight.dtype)\n","X_test = X_test.to(model.fc1.weight.dtype)\n","\n","# Assigning more weight to minority classes\n","total = 116 + 268 + 5000 # Total number of samples\n","weight_0 = (1-total/116) # Weight for class 0\n","weight_1 = (1-total/268) # Weight for class 1\n","weight_2 = (1-total/5000) # Weight for class 2\n","weight = torch.tensor([weight_2, weight_1, weight_0]) # Tensor of class weights\n","\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss(weight=weight)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n"]},{"cell_type":"code","execution_count":125,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":127088,"status":"ok","timestamp":1705489817725,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"N85LlaLOlFKO","outputId":"57fe752e-f4a9-439e-816b-aada4d317a77"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100, Loss: 17.4747\n","Epoch 2/100, Loss: 1.7716\n","Epoch 3/100, Loss: 2.2630\n","Epoch 4/100, Loss: 2.3510\n","Epoch 5/100, Loss: 2.1964\n","Epoch 6/100, Loss: 1.8086\n","Epoch 7/100, Loss: 1.2183\n","Epoch 8/100, Loss: 0.4551\n","Epoch 9/100, Loss: 22.5478\n","Epoch 10/100, Loss: 1.0092\n","Epoch 11/100, Loss: 2.2920\n","Epoch 12/100, Loss: 3.4274\n","Epoch 13/100, Loss: 4.4289\n","Epoch 14/100, Loss: 5.3080\n","Epoch 15/100, Loss: 6.0748\n","Epoch 16/100, Loss: 6.7382\n","Epoch 17/100, Loss: 7.3063\n","Epoch 18/100, Loss: 7.7864\n","Epoch 19/100, Loss: 8.1852\n","Epoch 20/100, Loss: 8.5089\n","Epoch 21/100, Loss: 8.7633\n","Epoch 22/100, Loss: 8.9538\n","Epoch 23/100, Loss: 9.0855\n","Epoch 24/100, Loss: 9.1629\n","Epoch 25/100, Loss: 9.1905\n","Epoch 26/100, Loss: 9.1723\n","Epoch 27/100, Loss: 9.1123\n","Epoch 28/100, Loss: 9.0140\n","Epoch 29/100, Loss: 8.8808\n","Epoch 30/100, Loss: 8.7157\n","Epoch 31/100, Loss: 8.5218\n","Epoch 32/100, Loss: 8.3017\n","Epoch 33/100, Loss: 8.0579\n","Epoch 34/100, Loss: 7.7927\n","Epoch 35/100, Loss: 7.5084\n","Epoch 36/100, Loss: 7.2068\n","Epoch 37/100, Loss: 6.8899\n","Epoch 38/100, Loss: 6.5591\n","Epoch 39/100, Loss: 6.2162\n","Epoch 40/100, Loss: 5.8624\n","Epoch 41/100, Loss: 5.4991\n","Epoch 42/100, Loss: 5.1272\n","Epoch 43/100, Loss: 4.7479\n","Epoch 44/100, Loss: 4.3621\n","Epoch 45/100, Loss: 3.9705\n","Epoch 46/100, Loss: 3.5738\n","Epoch 47/100, Loss: 3.1726\n","Epoch 48/100, Loss: 2.7674\n","Epoch 49/100, Loss: 2.3587\n","Epoch 50/100, Loss: 1.9468\n","Epoch 51/100, Loss: 1.5319\n","Epoch 52/100, Loss: 1.1144\n","Epoch 53/100, Loss: 0.6942\n","Epoch 54/100, Loss: 0.2715\n","Epoch 55/100, Loss: 8.9594\n","Epoch 56/100, Loss: 1.1031\n","Epoch 57/100, Loss: 2.2100\n","Epoch 58/100, Loss: 3.1804\n","Epoch 59/100, Loss: 4.0266\n","Epoch 60/100, Loss: 4.7596\n","Epoch 61/100, Loss: 5.3892\n","Epoch 62/100, Loss: 5.9244\n","Epoch 63/100, Loss: 6.3736\n","Epoch 64/100, Loss: 6.7443\n","Epoch 65/100, Loss: 7.0434\n","Epoch 66/100, Loss: 7.2768\n","Epoch 67/100, Loss: 7.4505\n","Epoch 68/100, Loss: 7.5705\n","Epoch 69/100, Loss: 7.6418\n","Epoch 70/100, Loss: 7.6692\n","Epoch 71/100, Loss: 7.6566\n","Epoch 72/100, Loss: 7.6082\n","Epoch 73/100, Loss: 7.5275\n","Epoch 74/100, Loss: 7.4177\n","Epoch 75/100, Loss: 7.2819\n","Epoch 76/100, Loss: 7.1230\n","Epoch 77/100, Loss: 6.9433\n","Epoch 78/100, Loss: 6.7454\n","Epoch 79/100, Loss: 6.5311\n","Epoch 80/100, Loss: 6.3026\n","Epoch 81/100, Loss: 6.0616\n","Epoch 82/100, Loss: 5.8095\n","Epoch 83/100, Loss: 5.5479\n","Epoch 84/100, Loss: 5.2780\n","Epoch 85/100, Loss: 5.0010\n","Epoch 86/100, Loss: 4.7179\n","Epoch 87/100, Loss: 4.4298\n","Epoch 88/100, Loss: 4.1381\n","Epoch 89/100, Loss: 3.8427\n","Epoch 90/100, Loss: 3.5442\n","Epoch 91/100, Loss: 3.2433\n","Epoch 92/100, Loss: 2.9406\n","Epoch 93/100, Loss: 2.6363\n","Epoch 94/100, Loss: 2.3308\n","Epoch 95/100, Loss: 2.0243\n","Epoch 96/100, Loss: 1.7170\n","Epoch 97/100, Loss: 1.4091\n","Epoch 98/100, Loss: 1.1008\n","Epoch 99/100, Loss: 0.7920\n","Epoch 100/100, Loss: 0.4829\n","Training Accuracy: 92.96%\n","Testing Accuracy: 92.02%\n"]}],"source":["#------------------------ Train and evaluate the model ------------------------\n","\n","\n","# Train the model\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    outputs = model(X_train)\n","    loss = criterion(outputs, y_train)\n","    loss.backward()\n","    optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n","\n","# Evaluate the model\n","with torch.no_grad():\n","    train_outputs = model(X_train)\n","    train_predictions = torch.argmax(train_outputs, dim=1)\n","    train_accuracy = (train_predictions == y_train).float().mean()\n","\n","    test_outputs = model(X_test)\n","    test_predictions = torch.argmax(test_outputs, dim=1)\n","    test_accuracy = (test_predictions == y_test).float().mean()\n","\n","\n","print(\"Training Accuracy: {:.2f}%\".format(train_accuracy * 100))\n","print(\"Testing Accuracy: {:.2f}%\".format(test_accuracy * 100))\n","\n"]},{"cell_type":"code","execution_count":126,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":751},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1705489821928,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"uggao7BalQa1","outputId":"dd9af834-c49d-4350-da01-b28b46f0d60c"},"outputs":[{"name":"stdout","output_type":"stream","text":["     Actual  Predicted\n","0         2          2\n","1         2          2\n","2         2          2\n","3         2          2\n","4         1          2\n","..      ...        ...\n","534       0          2\n","535       2          2\n","536       2          2\n","537       2          2\n","538       2          2\n","\n","[539 rows x 2 columns]\n","Correct predictions: 496\n","Total predictions: 539\n","Accuracy: 0.92\n","Total predictions per class: (array([2], dtype=int64), array([539], dtype=int64))\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#------------------------ Analyze predictions ------------------------\n","\n","\n","# Create and print new df with actual and predicted value for test set\n","df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': test_predictions.flatten()})\n","print(df)\n","\n","# Save the dataframe to a CSV file\n","df.to_csv('predictions_cl.csv', index=False)\n","\n","\n","# Calculate difference between actual and predicted values\n","df['Difference'] = (df['Actual'] - df['Predicted'])\n","\n","# Calculate accuracy\n","count = (df['Difference'] == 0.00).sum()\n","print(\"Correct predictions:\", count)\n","print(\"Total predictions:\", len(df))\n","print(\"Accuracy:\", (count / len(df)).round(2))\n","\n","# Check the count of each class in df['Predicted']\n","print(\"Total predictions per class:\", np.unique(df['Predicted'], return_counts=True))\n","\n","# NB the model ALWAYS predicts 2, given the high frequency of its occurence in the training set\n","\n","# Plot actual and predicted values with histogram\n","plt.hist([df['Actual'], df['Predicted']], label=['Actual', 'Predicted'])\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"I-V-NrFEoPSi"},"source":["# Random Forest\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jEkVHw4doO62"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","#------------------------ Create and train the model ------------------------\n","\n","# Create and fit a random forest regressor\n","rfr = RandomForestRegressor(n_estimators=100, random_state=42)\n","rfr.fit(X_train, y_train.ravel()) # use ravel to flatten y_train\n","\n","# Make predictions on the test set\n","y_pred = rfr.predict(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1705415875312,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"AtZktpG9sI7v","outputId":"07abe767-17bc-490c-f82b-17a5e16f07c2"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Analyze predictions ------------------------\n","\n","# Evaluate the model performance\n","rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","print(f\"Root Mean Squared Error: {rmse:.2f}\")\n","\n","# MAE\n","mae = mean_absolute_error(y_test, y_pred)\n","print(f\"Mean Absolute Error: {mae:.2f}\")\n","\n","# Accuracy\n","accuracy = rfr.score(X_test, y_test)\n","print(f\"Raw Accuracy: {accuracy:.2f}\")\n","\n","# Create new csv with actual and predicted data\n","df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': np.round(y_pred, 0)})\n","\n","# Add the difference column\n","df['Difference'] = df['Actual'] - df['Predicted']\n","\n","# Calculate accuracy of the model after rounding to the nearest integer\n","accuracy = (df['Difference'] == 0.00).sum() / len(df)\n","print(f\"Adjusted Accuracy: {accuracy:.2f}\")\n","\n","# Save the dataframe to a CSV file\n","df.to_csv('predictions_rf.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"executionInfo":{"elapsed":517,"status":"ok","timestamp":1705415862223,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"ACRT9Cg_sLZk","outputId":"97f605aa-7552-447a-f968-e0c442e50ef7"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Plot predictions ------------------------\n","\n","# Plot actual and predicted values with histogram\n","plt.hist([df['Actual'], df['Predicted']], label=['Actual', 'Predicted'])\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"S0P5kqYYa15g"},"source":["# Neural Network with replicated rows"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13908,"status":"ok","timestamp":1705476669725,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"xVWUofdVPcZD","outputId":"b96a92ea-35fb-4ee0-ed41-85f0459d4644"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","\n","\n","#------------------------ Load and preprocess the data ------------------------\n","\n","\n","df = pd.read_csv('/content/drive/MyDrive/Sensors/postgres_new_data.csv')\n","\n","# Generate the column names as rv1, rv2, ..., rv1500\n","col_names = [f'rv{i}' for i in range(1, 1501)]\n","\n","# Split the rv column by comma into a list of Series\n","split_series = df['rv'].str.split(',', n=1499, expand=True).apply(pd.Series)\n","\n","# Concatenate the original DataFrame with the split Series\n","df = pd.concat([df, split_series], axis=1)\n","\n","# Rename the split columns\n","df.rename(columns=dict(zip(split_series.columns, col_names)), inplace=True)\n","\n","# Drop the original 'rv' column\n","df.drop('rv', axis=1, inplace=True)\n","\n","# Remove ALL Nan rows\n","df.dropna(axis=0, how='all', inplace=True)\n","\n","# Replicate 4 times class 1 and 5 times class 0\n","df_replicated = pd.concat([df[df['ae_cl'] == 1]] * 4 + [df[df['ae_cl'] == 0]] * 5)\n","\n","# Add the replicated rows to the original DataFrame\n","df = pd.concat([df, df_replicated])\n","\n","print(df.shape)\n","\n","# Check if there are any Nan rows\n","nan_rows = df[df.isnull().any(axis=1)]\n","if nan_rows.empty:\n","    print(\"There are no NaN rows\")\n","else:\n","    print(\"There are NaN rows\")\n","\n","# Check ae_cl count\n","print(df['ae_cl'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fwnLChdPcZE"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Define the features and labels ------------------------\n","\n","\n","\n","X = df.loc[:, 'rv1':'rv1500'].astype(float).values\n","# X = df[col_names].astype(float).values\n","y = df['ae_cl']\n","\n","# Create a mask that is True for non-nan values and False for nan values\n","mask = ~np.isnan(y)\n","\n","# Apply the mask to both X and y\n","X = X[mask]\n","y = y[mask]\n","\n","# Check the count of each class in y\n","print(np.unique(y, return_counts=True))\n","\n","# Convert the data to tensors\n","X_tensor = torch.from_numpy(X)\n","y_tensor = torch.LongTensor(np.squeeze(y.values).astype(int)) # use np.squeeze on the values attribute\n","\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":239,"status":"ok","timestamp":1705490321483,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"pIqKDPfgPcZF"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Define the neural network model ------------------------\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.conv1 = nn.Conv1d(1, 3, 3) # Convolutional layer with 1 input channel, 3 output channels, and filter size 3\n","        self.fc2 = nn.Linear(4494, 3) # Linear layer with 4494 input features and 3 output units\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), 1, -1) # Reshape the input to have a channel dimension\n","        x = torch.relu(self.conv1(x)) # Apply ReLU activation to the convolutional layer\n","        x = x.view(x.size(0), -1) # Flatten the output to have a feature dimension\n","        x = self.fc2(x) # Apply linear transformation to the output layer\n","        return x # Return the logits without softmax\n","\n","\n","# Create an instance of the neural network model\n","model = NeuralNetwork()\n","\n","# Cast X_train and X_test to the same data type as model.fc1.weight\n","X_train = X_train.to(model.conv1.weight.dtype)\n","X_test = X_test.to(model.conv1.weight.dtype)\n","\n","\n","# Assigning more weight to minority classes\n","total = 696 + 1340 + 5000 # Total number of samples\n","weight_0 = total / 696 # Weight for class 0\n","weight_1 = total / 1340 # Weight for class 1\n","weight_2 = total / 5000 # Weight for class 2\n","weight = torch.tensor([weight_0, weight_1, weight_2]) # Tensor of class weights\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss(weight=weight)\n","optimizer = optim.Adam(model.parameters(), lr=0.000001)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":111279,"status":"ok","timestamp":1705490436238,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"y1JqxYHUPcZF","outputId":"49db14c5-7f86-4fa5-96e9-9102e680516f"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Train and evaluate the model ------------------------\n","\n","\n","# Train the model\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    outputs = model(X_train)\n","    loss = criterion(outputs, y_train)\n","    loss.backward()\n","    optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n","\n","\n","# Evaluate the model\n","with torch.no_grad():\n","    train_outputs = model(X_train)\n","    train_predictions = torch.argmax(train_outputs, dim=1)\n","    train_accuracy = (train_predictions == y_train).float().mean()\n","\n","    test_outputs = model(X_test)\n","    test_predictions = torch.argmax(test_outputs, dim=1)\n","    test_accuracy = (test_predictions == y_test).float().mean()\n","\n","\n","print(\"Training Accuracy: {:.2f}%\".format(train_accuracy * 100))\n","print(\"Testing Accuracy: {:.2f}%\".format(test_accuracy * 100))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":751},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1705490439135,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"A7GwX6vDPcZF","outputId":"ec5ce090-05ab-4d87-93cf-2cf293839980"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Analyze predictions ------------------------\n","\n","\n","# Create and print new df with actual and predicted value for test set\n","df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': test_predictions.flatten()})\n","print(df)\n","\n","# Save the dataframe to a CSV file\n","df.to_csv('predictions_cl.csv', index=False)\n","\n","\n","# Calculate difference between actual and predicted values\n","df['Difference'] = (df['Actual'] - df['Predicted'])\n","\n","# Calculate accuracy\n","count = (df['Difference'] == 0.00).sum()\n","print(\"Correct predictions:\", count)\n","print(\"Total predictions:\", len(df))\n","print(\"Accuracy:\", (count / len(df)).round(2))\n","\n","# Check the count of each class in df['Predicted']\n","print(\"Total predictions per class:\", np.unique(df['Predicted'], return_counts=True))\n","\n","# NB the model ALWAYS predicts 2, given the high frequency of its occurence in the training set\n","\n","# Plot actual and predicted values with histogram\n","plt.hist([df['Actual'], df['Predicted']], label=['Actual', 'Predicted'])\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"TpZ4qilOPcZG"},"source":["# Random Forest\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":106137,"status":"ok","timestamp":1705479224725,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"vvZT52--egWb"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","#------------------------ Create and train the model ------------------------\n","\n","# Create and fit a random forest regressor\n","rfr = RandomForestRegressor(n_estimators=100, random_state=42)\n","rfr.fit(X_train, y_train.ravel()) # use ravel to flatten y_train\n","\n","# Make predictions on the test set\n","y_pred = rfr.predict(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":233,"status":"ok","timestamp":1705479257182,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"9SXx8YpJegWb","outputId":"377580f2-f61a-4f91-a6ef-dd723fe9e8e3"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Analyze predictions ------------------------\n","\n","# Evaluate the model performance\n","rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","print(f\"Root Mean Squared Error: {rmse:.2f}\")\n","\n","# MAE\n","mae = mean_absolute_error(y_test, y_pred)\n","print(f\"Mean Absolute Error: {mae:.2f}\")\n","\n","# Accuracy\n","accuracy = rfr.score(X_test, y_test)\n","print(f\"Raw Accuracy: {accuracy:.2f}\")\n","\n","# Create new csv with actual and predicted data\n","df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': np.round(y_pred, 0)})\n","\n","# Add the difference column\n","df['Difference'] = df['Actual'] - df['Predicted']\n","\n","# Calculate accuracy of the model after rounding to the nearest integer\n","accuracy = (df['Difference'] == 0.00).sum() / len(df)\n","print(f\"Adjusted Accuracy: {accuracy:.2f}\")\n","\n","# Save the dataframe to a CSV file\n","df.to_csv('predictions_rf.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"executionInfo":{"elapsed":640,"status":"ok","timestamp":1705479262711,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"jW2wixnCegWc","outputId":"c8923225-9d23-487f-a03d-75e4debd8d8e"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Plot predictions ------------------------\n","\n","# Plot actual and predicted values with histogram\n","plt.hist([df['Actual'], df['Predicted']], label=['Actual', 'Predicted'])\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cI0Y2iRyFTS"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Predict single  ------------------------\n","\n","\n","# Convert the row into a numpy array and reshape it to have the same shape as X_train\n","#row = np.array(row).reshape(1, 1500)\n","\n","# Predict the class of the row using the model\n","#cl = int(rfr.predict(row))\n","\n","# Print the result\n","#print(f\"The predicted class of the row is {cl}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1705489903657,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"uQxqvNlJHobB","outputId":"c2d61818-9d22-4e6e-ec46-a341f5354d38"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   slope\n","0    1.0\n","1    2.0\n","2    3.0\n","3    4.0\n","4    5.0\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LinearRegression\n","\n","# Create a sample DataFrame\n","data = {'c1': [1, 2, 3, 4, 5],\n","        'c2': [2, 4, 6, 8, 10],\n","        'c3': [3, 6, 9, 12, 15],\n","        'c4': [4, 8, 12, 16, 20],\n","        'c5': [5, 10, 15, 20, 25],\n","        }\n","\n","df = pd.DataFrame(data)\n","\n","# Specify the columns to include in the linear regression (exclude 'c1' and 'c2')\n","columns_to_include = ['c3', 'c4', 'c5']\n","\n","# Create an instance of LinearRegression\n","model = LinearRegression()\n","\n","# Function to get coefficient for each row\n","def get_coeff(row, model=model):\n","    # Select only relevant columns\n","    row = row.loc[columns_to_include]\n","    \n","    # Drop NaN values\n","    row = row.dropna()\n","    \n","    if len(row) > 1:  # Check if there are enough data points for regression\n","        X = np.arange(len(row)).reshape(-1, 1)\n","        y = row.values.reshape(-1, 1)\n","        model.fit(X, y)\n","        slope = model.coef_[0][0]\n","        return slope\n","    else:\n","        return np.nan  # Return NaN if there are not enough data points\n","\n","# Apply the function to each row to get only the slope values\n","df['slope'] = df.apply(get_coeff, axis=1)\n","\n","print(df[['slope']])\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPhPH9KC52rl2jSW0Xjx3WV","gpuType":"T4","mount_file_id":"12RBqsdsW6ybtYghxXZflWeEbTXLfT92g","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}
