{"cells":[{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"elapsed":6496,"status":"ok","timestamp":1705414457751,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"naqgmGruWck9","outputId":"940c23a2-75af-4c0e-af63-cc9295e82c1b"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.stats import linregress\n","from matplotlib.colors import ListedColormap\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"ename":"EmptyDataError","evalue":"No columns to parse from file","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn [20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#------------------------ Load and preprocess the data ------------------------\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata-postgres_data_15000_rv_sens_all.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     78\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:554\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n","\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"]}],"source":["#------------------------ Load and preprocess the data ------------------------\n","df = pd.read_csv('data-postgres_data_15000_rv_sens_all.csv')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Generate the column names as rv1, rv2, ..., rv1500\n","col_names = [f'rv{i}' for i in range(1, 1501)]\n","\n","# Split the rv column by comma into a list of Series\n","split_series = df['rv'].str.split(',', n=1499, expand=True).apply(pd.Series)\n","\n","# Concatenate the original DataFrame with the split Series\n","df = pd.concat([df, split_series], axis=1)\n","\n","# Rename the split columns\n","df.rename(columns=dict(zip(split_series.columns, col_names)), inplace=True)\n","\n","df.head()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["#column_names = df.columns.tolist()\n","# Columns to remove\n","#columns_to_remove = ['tm','knt','ae','ae_cl','rv']\n","#numeric_columns = list(set(column_names).difference(columns_to_remove))\n","#numeric_columns = list(filter(lambda col: col not in columns_to_remove, column_names))\n","numeric_columns = [f'rv{i}' for i in range(1, 1501)]\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["\n","model = LinearRegression()\n","def get_coeff(row, model=model):\n","    # Select only relevant columns\n","    row = row.loc[numeric_columns]\n","    # Drop NaN values\n","    row = row.dropna()\n","    if len(row) > 1:  # Check if there are enough data points for regression\n","        X = np.arange(len(row)).reshape(-1, 1)\n","        y = row.values.reshape(-1, 1)\n","        model.fit(X, y)\n","        slope = model.coef_[0][0]\n","        return slope\n","    else:\n","        return np.nan  # Return "]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tm</th>\n","      <th>knt</th>\n","      <th>ae</th>\n","      <th>ae_cl</th>\n","      <th>rv</th>\n","      <th>rv1</th>\n","      <th>rv2</th>\n","      <th>rv3</th>\n","      <th>rv4</th>\n","      <th>rv5</th>\n","      <th>...</th>\n","      <th>rv1493</th>\n","      <th>rv1494</th>\n","      <th>rv1495</th>\n","      <th>rv1496</th>\n","      <th>rv1497</th>\n","      <th>rv1498</th>\n","      <th>rv1499</th>\n","      <th>rv1500</th>\n","      <th>mn</th>\n","      <th>ds</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-10-13 02:02:26.816014</td>\n","      <td>1500</td>\n","      <td>0.997571</td>\n","      <td>2</td>\n","      <td>57.372899999999994, 70.80059999999999, 25.6347...</td>\n","      <td>57.372899999999994</td>\n","      <td>70.80059999999999</td>\n","      <td>25.6347</td>\n","      <td>23.193299999999997</td>\n","      <td>19.5312</td>\n","      <td>...</td>\n","      <td>32.9589</td>\n","      <td>17.089799999999997</td>\n","      <td>23.193299999999997</td>\n","      <td>18.310499999999998</td>\n","      <td>14.648399999999999</td>\n","      <td>20.7519</td>\n","      <td>12.206999999999999</td>\n","      <td>14.648399999999999</td>\n","      <td>500.999190</td>\n","      <td>706.400365</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2022-10-13 02:05:23.409857</td>\n","      <td>1500</td>\n","      <td>0.996345</td>\n","      <td>2</td>\n","      <td>23.193299999999997, 20.7519, 0, 19.5312, 36.62...</td>\n","      <td>23.193299999999997</td>\n","      <td>20.7519</td>\n","      <td>0</td>\n","      <td>19.5312</td>\n","      <td>36.620999999999995</td>\n","      <td>...</td>\n","      <td>24.413999999999998</td>\n","      <td>25.6347</td>\n","      <td>32.9589</td>\n","      <td>20.7519</td>\n","      <td>15.8691</td>\n","      <td>36.620999999999995</td>\n","      <td>70.80059999999999</td>\n","      <td>28.076099999999997</td>\n","      <td>500.998782</td>\n","      <td>706.400655</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2022-10-13 02:08:20.002696</td>\n","      <td>1500</td>\n","      <td>0.991370</td>\n","      <td>2</td>\n","      <td>23.193299999999997, 17.089799999999997, 20.751...</td>\n","      <td>23.193299999999997</td>\n","      <td>17.089799999999997</td>\n","      <td>20.7519</td>\n","      <td>28.076099999999997</td>\n","      <td>21.9726</td>\n","      <td>...</td>\n","      <td>14.648399999999999</td>\n","      <td>0</td>\n","      <td>19.5312</td>\n","      <td>12.206999999999999</td>\n","      <td>24.413999999999998</td>\n","      <td>19.5312</td>\n","      <td>6.1034999999999995</td>\n","      <td>0</td>\n","      <td>500.997123</td>\n","      <td>706.401829</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022-10-13 02:11:16.595751</td>\n","      <td>1500</td>\n","      <td>0.991370</td>\n","      <td>2</td>\n","      <td>18.310499999999998, 9.7656, 0, 23.193299999999...</td>\n","      <td>18.310499999999998</td>\n","      <td>9.7656</td>\n","      <td>0</td>\n","      <td>23.193299999999997</td>\n","      <td>26.855399999999996</td>\n","      <td>...</td>\n","      <td>14.648399999999999</td>\n","      <td>19.5312</td>\n","      <td>18.310499999999998</td>\n","      <td>20.7519</td>\n","      <td>21.9726</td>\n","      <td>0</td>\n","      <td>15.8691</td>\n","      <td>13.427699999999998</td>\n","      <td>500.997123</td>\n","      <td>706.401829</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2022-10-13 02:14:13.189162</td>\n","      <td>1500</td>\n","      <td>0.990989</td>\n","      <td>2</td>\n","      <td>10.9863, 24.413999999999998, 14.64839999999999...</td>\n","      <td>10.9863</td>\n","      <td>24.413999999999998</td>\n","      <td>14.648399999999999</td>\n","      <td>73.24199999999999</td>\n","      <td>21.9726</td>\n","      <td>...</td>\n","      <td>62.2557</td>\n","      <td>21.9726</td>\n","      <td>19.5312</td>\n","      <td>30.5175</td>\n","      <td>20.7519</td>\n","      <td>24.413999999999998</td>\n","      <td>39.0624</td>\n","      <td>15.8691</td>\n","      <td>500.996996</td>\n","      <td>706.401918</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1507 columns</p>\n","</div>"],"text/plain":["                           tm   knt        ae  ae_cl  \\\n","0  2022-10-13 02:02:26.816014  1500  0.997571      2   \n","1  2022-10-13 02:05:23.409857  1500  0.996345      2   \n","2  2022-10-13 02:08:20.002696  1500  0.991370      2   \n","3  2022-10-13 02:11:16.595751  1500  0.991370      2   \n","4  2022-10-13 02:14:13.189162  1500  0.990989      2   \n","\n","                                                  rv                 rv1  \\\n","0  57.372899999999994, 70.80059999999999, 25.6347...  57.372899999999994   \n","1  23.193299999999997, 20.7519, 0, 19.5312, 36.62...  23.193299999999997   \n","2  23.193299999999997, 17.089799999999997, 20.751...  23.193299999999997   \n","3  18.310499999999998, 9.7656, 0, 23.193299999999...  18.310499999999998   \n","4  10.9863, 24.413999999999998, 14.64839999999999...             10.9863   \n","\n","                   rv2                  rv3                  rv4  \\\n","0    70.80059999999999              25.6347   23.193299999999997   \n","1              20.7519                    0              19.5312   \n","2   17.089799999999997              20.7519   28.076099999999997   \n","3               9.7656                    0   23.193299999999997   \n","4   24.413999999999998   14.648399999999999    73.24199999999999   \n","\n","                   rv5  ...               rv1493               rv1494  \\\n","0              19.5312  ...              32.9589   17.089799999999997   \n","1   36.620999999999995  ...   24.413999999999998              25.6347   \n","2              21.9726  ...   14.648399999999999                    0   \n","3   26.855399999999996  ...   14.648399999999999              19.5312   \n","4              21.9726  ...              62.2557              21.9726   \n","\n","                rv1495               rv1496               rv1497  \\\n","0   23.193299999999997   18.310499999999998   14.648399999999999   \n","1              32.9589              20.7519              15.8691   \n","2              19.5312   12.206999999999999   24.413999999999998   \n","3   18.310499999999998              20.7519              21.9726   \n","4              19.5312              30.5175              20.7519   \n","\n","                rv1498               rv1499               rv1500          mn  \\\n","0              20.7519   12.206999999999999   14.648399999999999  500.999190   \n","1   36.620999999999995    70.80059999999999   28.076099999999997  500.998782   \n","2              19.5312   6.1034999999999995                    0  500.997123   \n","3                    0              15.8691   13.427699999999998  500.997123   \n","4   24.413999999999998              39.0624              15.8691  500.996996   \n","\n","           ds  \n","0  706.400365  \n","1  706.400655  \n","2  706.401829  \n","3  706.401829  \n","4  706.401918  \n","\n","[5 rows x 1507 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["\n","# df['mn'] = df.select_dtypes(include='number').mean(axis=1,skipna=True)\n","# df['ds'] = df.select_dtypes(include='number').std(axis=1, skipna=True)\n","# df.head()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tm</th>\n","      <th>knt</th>\n","      <th>ae</th>\n","      <th>ae_cl</th>\n","      <th>rv1</th>\n","      <th>rv2</th>\n","      <th>rv3</th>\n","      <th>rv4</th>\n","      <th>rv5</th>\n","      <th>rv6</th>\n","      <th>...</th>\n","      <th>rv1494</th>\n","      <th>rv1495</th>\n","      <th>rv1496</th>\n","      <th>rv1497</th>\n","      <th>rv1498</th>\n","      <th>rv1499</th>\n","      <th>rv1500</th>\n","      <th>mn</th>\n","      <th>ds</th>\n","      <th>slope</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-10-13 03:38:11.838465</td>\n","      <td>1500</td>\n","      <td>0.109208</td>\n","      <td>0</td>\n","      <td>26.0026</td>\n","      <td>25.0025</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>...</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>25.0025</td>\n","      <td>26.0026</td>\n","      <td>26.0026</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-0.000023</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2022-10-13 13:30:49.852566</td>\n","      <td>1500</td>\n","      <td>0.317388</td>\n","      <td>0</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>...</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-0.000047</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2022-10-13 14:17:07.820202</td>\n","      <td>1500</td>\n","      <td>0.300354</td>\n","      <td>0</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>...</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>25.0025</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-0.000024</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022-09-07 23:13:37.665544</td>\n","      <td>1500</td>\n","      <td>0.179053</td>\n","      <td>0</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>...</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.000035</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2022-09-07 23:25:58.593231</td>\n","      <td>1500</td>\n","      <td>0.300354</td>\n","      <td>0</td>\n","      <td>27.0027</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>27.0027</td>\n","      <td>28.0028</td>\n","      <td>...</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>28.0028</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.000014</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1507 columns</p>\n","</div>"],"text/plain":["                           tm   knt        ae  ae_cl      rv1       rv2  \\\n","0  2022-10-13 03:38:11.838465  1500  0.109208      0  26.0026   25.0025   \n","1  2022-10-13 13:30:49.852566  1500  0.317388      0  25.0025   25.0025   \n","2  2022-10-13 14:17:07.820202  1500  0.300354      0  25.0025   25.0025   \n","3  2022-09-07 23:13:37.665544  1500  0.179053      0  28.0028   28.0028   \n","4  2022-09-07 23:25:58.593231  1500  0.300354      0  27.0027   28.0028   \n","\n","        rv3       rv4       rv5       rv6  ...    rv1494    rv1495    rv1496  \\\n","0   26.0026   26.0026   26.0026   26.0026  ...   26.0026   26.0026   26.0026   \n","1   25.0025   25.0025   25.0025   25.0025  ...   25.0025   25.0025   25.0025   \n","2   25.0025   25.0025   25.0025   25.0025  ...   25.0025   25.0025   25.0025   \n","3   28.0028   28.0028   28.0028   28.0028  ...   28.0028   28.0028   28.0028   \n","4   28.0028   28.0028   27.0027   28.0028  ...   28.0028   28.0028   28.0028   \n","\n","     rv1497    rv1498    rv1499    rv1500  mn  ds     slope  \n","0   26.0026   25.0025   26.0026   26.0026 NaN NaN -0.000023  \n","1   25.0025   25.0025   25.0025   25.0025 NaN NaN -0.000047  \n","2   25.0025   25.0025   25.0025   25.0025 NaN NaN -0.000024  \n","3   28.0028   28.0028   28.0028   28.0028 NaN NaN  0.000035  \n","4   28.0028   28.0028   28.0028   28.0028 NaN NaN  0.000014  \n","\n","[5 rows x 1507 columns]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["\n","# df[\"slope\"] = df.apply(get_coeff, axis=1)\n","# Drop the original 'rv' column\n","# df.drop('rv', axis=1, inplace=True)\n","# df.head()"]},{"cell_type":"code","execution_count":133,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1705414457752,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"wzuf8zS4fys4","outputId":"c65c07a4-d509-46bb-ffd3-aac9b771ce63"},"outputs":[{"ename":"KeyError","evalue":"'rv1'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","\u001b[1;31mKeyError\u001b[0m: 'rv1'","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[1;32mIn [133], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#------------------------ Define the features and labels ------------------------\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrv1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrv1500\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# X = df[col_names].astype(float).values\u001b[39;00m\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mae_cl\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1066\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexing.py:1256\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    922\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 924\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexing.py:1290\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_slice_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getbool_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexing.py:1324\u001b[0m, in \u001b[0;36m_LocIndexer._get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1323\u001b[0m labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1324\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39maxis)\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6559\u001b[0m, in \u001b[0;36mIndex.slice_indexer\u001b[1;34m(self, start, end, step, kind)\u001b[0m\n\u001b[0;32m   6516\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6517\u001b[0m \u001b[38;5;124;03mCompute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[0;32m   6518\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6555\u001b[0m \u001b[38;5;124;03mslice(1, 3, None)\u001b[39;00m\n\u001b[0;32m   6556\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deprecated_arg(kind, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice_indexer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 6559\u001b[0m start_slice, end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_locs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6561\u001b[0m \u001b[38;5;66;03m# return a slice\u001b[39;00m\n\u001b[0;32m   6562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(start_slice):\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6767\u001b[0m, in \u001b[0;36mIndex.slice_locs\u001b[1;34m(self, start, end, step, kind)\u001b[0m\n\u001b[0;32m   6765\u001b[0m start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   6766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 6767\u001b[0m     start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_slice_bound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_slice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   6769\u001b[0m     start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6686\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side, kind)\u001b[0m\n\u001b[0;32m   6683\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_searchsorted_monotonic(label, side)\n\u001b[0;32m   6684\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   6685\u001b[0m         \u001b[38;5;66;03m# raise the original KeyError\u001b[39;00m\n\u001b[1;32m-> 6686\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m   6688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(slc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   6689\u001b[0m     \u001b[38;5;66;03m# get_loc may return a boolean array, which\u001b[39;00m\n\u001b[0;32m   6690\u001b[0m     \u001b[38;5;66;03m# is OK as long as they are representable by a slice.\u001b[39;00m\n\u001b[0;32m   6691\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m is_bool_dtype(slc\u001b[38;5;241m.\u001b[39mdtype)\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6680\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side, kind)\u001b[0m\n\u001b[0;32m   6678\u001b[0m \u001b[38;5;66;03m# we need to look up the label\u001b[39;00m\n\u001b[0;32m   6679\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6680\u001b[0m     slc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   6682\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\stefa\\anaconda3\\envs\\py_Django\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[1;31mKeyError\u001b[0m: 'rv1'"]}],"source":["#------------------------ Define the features and labels ------------------------\n","\n","\n","\n","X = df.loc[:, 'rv1':'rv1500'].astype(float).values\n","X = df.loc[:, ['rv1', 'rv2', 'mn', 'ds']].astype(float).values\n","\n","# X = df[col_names].astype(float).values\n","y = df['ae_cl']\n","\n","# Create a mask that is True for non-nan values and False for nan values\n","mask = ~np.isnan(y)\n","\n","# Apply the mask to both X and y\n","X = X[mask]\n","y = y[mask]\n","\n","# Check the count of each class in y\n","print(np.unique(y, return_counts=True))\n","\n","# Convert the data to tensors\n","X_tensor = torch.from_numpy(X)\n","y_tensor = torch.LongTensor(y)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# X = df[col_names].astype(float).values\n","y = df['ae_cl']\n","\n","# Create a mask that is True for non-nan values and False for nan values\n","mask = ~np.isnan(y)\n","\n","# Apply the mask to both X and y\n","X = X[mask]\n","y = y[mask]\n","\n","# Check the count of each class in y\n","print(np.unique(y, return_counts=True))\n"]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[],"source":["\n","# Convert the data to tensors\n","X_tensor = torch.from_numpy(X)\n","y_tensor = torch.LongTensor(y)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(array([0, 1, 2], dtype=int64), array([ 116,  268, 5000], dtype=int64))\n"]}],"source":["\n","# Apply the mask to both X and y\n","X = X[mask]\n","y = y[mask]\n","\n","# Check the count of each class in y\n","print(np.unique(y, return_counts=True))\n","\n","# Convert the data to tensors\n","X_tensor = torch.from_numpy(X)\n","y_tensor = torch.LongTensor(y)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.1, random_state=42)\n"]},{"cell_type":"code","execution_count":123,"metadata":{"executionInfo":{"elapsed":219,"status":"ok","timestamp":1705489688253,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"qdr65VXwh_La"},"outputs":[],"source":["#------------------------ Define the neural network model ------------------------\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.fc1 = nn.Linear(1500, 512)  # Input layer with 1500 input features and 1500 hidden units\n","        self.fc2 = nn.Linear(512, 3)  # Hidden layer with 1500 units and 3 output units\n","        #self.softmax = nn.LogSoftmax.Softmax(dim=1)  # Softmax layer to get probabilities of each class\n","        self.softmax = nn.LogSoftmax(dim=1)  # Softmax layer to get probabilities of each class\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))  # Apply ReLU activation to the hidden layer\n","        x = self.fc2(x)  # Apply linear transformation to the output layer\n","        x = self.softmax(x)  # Apply softmax to get probabilities of each class\n","        \n","        return x\n","\n","\n","# Create an instance of the neural network model\n","model = NeuralNetwork()\n","\n","# Cast X_train and X_test to the same data type as model.fc1.weight\n","X_train = X_train.to(model.fc1.weight.dtype)\n","X_test = X_test.to(model.fc1.weight.dtype)\n","\n","# Assigning more weight to minority classes\n","total = 116 + 268 + 5000 # Total number of samples\n","weight_0 = total / 116 # Weight for class 0\n","weight_1 = total / 268 # Weight for class 1\n","weight_2 = total / 5000 # Weight for class 2\n","weight = torch.tensor([weight_0, weight_1, weight_2]) # Tensor of class weights\n","\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss(weight=weight)\n","optimizer = optim.Adam(model.parameters(), lr=0.00001)\n"]},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[],"source":["\n","# Create an instance of the neural network model\n","model = NeuralNetwork()\n","\n","# Cast X_train and X_test to the same data type as model.fc1.weight\n","X_train = X_train.to(model.fc1.weight.dtype)\n","X_test = X_test.to(model.fc1.weight.dtype)\n","\n","# Assigning more weight to minority classes\n","total = 116 + 268 + 5000 # Total number of samples\n","weight_0 = (1-total/116) # Weight for class 0\n","weight_1 = (1-total/268) # Weight for class 1\n","weight_2 = (1-total/5000) # Weight for class 2\n","weight = torch.tensor([weight_2, weight_1, weight_0]) # Tensor of class weights\n","\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss(weight=weight)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n"]},{"cell_type":"code","execution_count":125,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":127088,"status":"ok","timestamp":1705489817725,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"N85LlaLOlFKO","outputId":"57fe752e-f4a9-439e-816b-aada4d317a77"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100, Loss: 17.4747\n","Epoch 2/100, Loss: 1.7716\n","Epoch 3/100, Loss: 2.2630\n","Epoch 4/100, Loss: 2.3510\n","Epoch 5/100, Loss: 2.1964\n","Epoch 6/100, Loss: 1.8086\n","Epoch 7/100, Loss: 1.2183\n","Epoch 8/100, Loss: 0.4551\n","Epoch 9/100, Loss: 22.5478\n","Epoch 10/100, Loss: 1.0092\n","Epoch 11/100, Loss: 2.2920\n","Epoch 12/100, Loss: 3.4274\n","Epoch 13/100, Loss: 4.4289\n","Epoch 14/100, Loss: 5.3080\n","Epoch 15/100, Loss: 6.0748\n","Epoch 16/100, Loss: 6.7382\n","Epoch 17/100, Loss: 7.3063\n","Epoch 18/100, Loss: 7.7864\n","Epoch 19/100, Loss: 8.1852\n","Epoch 20/100, Loss: 8.5089\n","Epoch 21/100, Loss: 8.7633\n","Epoch 22/100, Loss: 8.9538\n","Epoch 23/100, Loss: 9.0855\n","Epoch 24/100, Loss: 9.1629\n","Epoch 25/100, Loss: 9.1905\n","Epoch 26/100, Loss: 9.1723\n","Epoch 27/100, Loss: 9.1123\n","Epoch 28/100, Loss: 9.0140\n","Epoch 29/100, Loss: 8.8808\n","Epoch 30/100, Loss: 8.7157\n","Epoch 31/100, Loss: 8.5218\n","Epoch 32/100, Loss: 8.3017\n","Epoch 33/100, Loss: 8.0579\n","Epoch 34/100, Loss: 7.7927\n","Epoch 35/100, Loss: 7.5084\n","Epoch 36/100, Loss: 7.2068\n","Epoch 37/100, Loss: 6.8899\n","Epoch 38/100, Loss: 6.5591\n","Epoch 39/100, Loss: 6.2162\n","Epoch 40/100, Loss: 5.8624\n","Epoch 41/100, Loss: 5.4991\n","Epoch 42/100, Loss: 5.1272\n","Epoch 43/100, Loss: 4.7479\n","Epoch 44/100, Loss: 4.3621\n","Epoch 45/100, Loss: 3.9705\n","Epoch 46/100, Loss: 3.5738\n","Epoch 47/100, Loss: 3.1726\n","Epoch 48/100, Loss: 2.7674\n","Epoch 49/100, Loss: 2.3587\n","Epoch 50/100, Loss: 1.9468\n","Epoch 51/100, Loss: 1.5319\n","Epoch 52/100, Loss: 1.1144\n","Epoch 53/100, Loss: 0.6942\n","Epoch 54/100, Loss: 0.2715\n","Epoch 55/100, Loss: 8.9594\n","Epoch 56/100, Loss: 1.1031\n","Epoch 57/100, Loss: 2.2100\n","Epoch 58/100, Loss: 3.1804\n","Epoch 59/100, Loss: 4.0266\n","Epoch 60/100, Loss: 4.7596\n","Epoch 61/100, Loss: 5.3892\n","Epoch 62/100, Loss: 5.9244\n","Epoch 63/100, Loss: 6.3736\n","Epoch 64/100, Loss: 6.7443\n","Epoch 65/100, Loss: 7.0434\n","Epoch 66/100, Loss: 7.2768\n","Epoch 67/100, Loss: 7.4505\n","Epoch 68/100, Loss: 7.5705\n","Epoch 69/100, Loss: 7.6418\n","Epoch 70/100, Loss: 7.6692\n","Epoch 71/100, Loss: 7.6566\n","Epoch 72/100, Loss: 7.6082\n","Epoch 73/100, Loss: 7.5275\n","Epoch 74/100, Loss: 7.4177\n","Epoch 75/100, Loss: 7.2819\n","Epoch 76/100, Loss: 7.1230\n","Epoch 77/100, Loss: 6.9433\n","Epoch 78/100, Loss: 6.7454\n","Epoch 79/100, Loss: 6.5311\n","Epoch 80/100, Loss: 6.3026\n","Epoch 81/100, Loss: 6.0616\n","Epoch 82/100, Loss: 5.8095\n","Epoch 83/100, Loss: 5.5479\n","Epoch 84/100, Loss: 5.2780\n","Epoch 85/100, Loss: 5.0010\n","Epoch 86/100, Loss: 4.7179\n","Epoch 87/100, Loss: 4.4298\n","Epoch 88/100, Loss: 4.1381\n","Epoch 89/100, Loss: 3.8427\n","Epoch 90/100, Loss: 3.5442\n","Epoch 91/100, Loss: 3.2433\n","Epoch 92/100, Loss: 2.9406\n","Epoch 93/100, Loss: 2.6363\n","Epoch 94/100, Loss: 2.3308\n","Epoch 95/100, Loss: 2.0243\n","Epoch 96/100, Loss: 1.7170\n","Epoch 97/100, Loss: 1.4091\n","Epoch 98/100, Loss: 1.1008\n","Epoch 99/100, Loss: 0.7920\n","Epoch 100/100, Loss: 0.4829\n","Training Accuracy: 92.96%\n","Testing Accuracy: 92.02%\n"]}],"source":["#------------------------ Train and evaluate the model ------------------------\n","\n","\n","# Train the model\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    outputs = model(X_train)\n","    loss = criterion(outputs, y_train)\n","    loss.backward()\n","    optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n","\n","# Evaluate the model\n","with torch.no_grad():\n","    train_outputs = model(X_train)\n","    train_predictions = torch.argmax(train_outputs, dim=1)\n","    train_accuracy = (train_predictions == y_train).float().mean()\n","\n","    test_outputs = model(X_test)\n","    test_predictions = torch.argmax(test_outputs, dim=1)\n","    test_accuracy = (test_predictions == y_test).float().mean()\n","\n","\n","print(\"Training Accuracy: {:.2f}%\".format(train_accuracy * 100))\n","print(\"Testing Accuracy: {:.2f}%\".format(test_accuracy * 100))\n","\n"]},{"cell_type":"code","execution_count":126,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":751},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1705489821928,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"uggao7BalQa1","outputId":"dd9af834-c49d-4350-da01-b28b46f0d60c"},"outputs":[{"name":"stdout","output_type":"stream","text":["     Actual  Predicted\n","0         2          2\n","1         2          2\n","2         2          2\n","3         2          2\n","4         1          2\n","..      ...        ...\n","534       0          2\n","535       2          2\n","536       2          2\n","537       2          2\n","538       2          2\n","\n","[539 rows x 2 columns]\n","Correct predictions: 496\n","Total predictions: 539\n","Accuracy: 0.92\n","Total predictions per class: (array([2], dtype=int64), array([539], dtype=int64))\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#------------------------ Analyze predictions ------------------------\n","\n","\n","# Create and print new df with actual and predicted value for test set\n","df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': test_predictions.flatten()})\n","print(df)\n","\n","# Save the dataframe to a CSV file\n","df.to_csv('predictions_cl.csv', index=False)\n","\n","\n","# Calculate difference between actual and predicted values\n","df['Difference'] = (df['Actual'] - df['Predicted'])\n","\n","# Calculate accuracy\n","count = (df['Difference'] == 0.00).sum()\n","print(\"Correct predictions:\", count)\n","print(\"Total predictions:\", len(df))\n","print(\"Accuracy:\", (count / len(df)).round(2))\n","\n","# Check the count of each class in df['Predicted']\n","print(\"Total predictions per class:\", np.unique(df['Predicted'], return_counts=True))\n","\n","# NB the model ALWAYS predicts 2, given the high frequency of its occurence in the training set\n","\n","# Plot actual and predicted values with histogram\n","plt.hist([df['Actual'], df['Predicted']], label=['Actual', 'Predicted'])\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"I-V-NrFEoPSi"},"source":["# Random Forest\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jEkVHw4doO62"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","#------------------------ Create and train the model ------------------------\n","\n","# Create and fit a random forest regressor\n","rfr = RandomForestRegressor(n_estimators=100, random_state=42)\n","rfr.fit(X_train, y_train.ravel()) # use ravel to flatten y_train\n","\n","# Make predictions on the test set\n","y_pred = rfr.predict(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1705415875312,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"AtZktpG9sI7v","outputId":"07abe767-17bc-490c-f82b-17a5e16f07c2"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Analyze predictions ------------------------\n","\n","# Evaluate the model performance\n","rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","print(f\"Root Mean Squared Error: {rmse:.2f}\")\n","\n","# MAE\n","mae = mean_absolute_error(y_test, y_pred)\n","print(f\"Mean Absolute Error: {mae:.2f}\")\n","\n","# Accuracy\n","accuracy = rfr.score(X_test, y_test)\n","print(f\"Raw Accuracy: {accuracy:.2f}\")\n","\n","# Create new csv with actual and predicted data\n","df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': np.round(y_pred, 0)})\n","\n","# Add the difference column\n","df['Difference'] = df['Actual'] - df['Predicted']\n","\n","# Calculate accuracy of the model after rounding to the nearest integer\n","accuracy = (df['Difference'] == 0.00).sum() / len(df)\n","print(f\"Adjusted Accuracy: {accuracy:.2f}\")\n","\n","# Save the dataframe to a CSV file\n","df.to_csv('predictions_rf.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"executionInfo":{"elapsed":517,"status":"ok","timestamp":1705415862223,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"ACRT9Cg_sLZk","outputId":"97f605aa-7552-447a-f968-e0c442e50ef7"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Plot predictions ------------------------\n","\n","# Plot actual and predicted values with histogram\n","plt.hist([df['Actual'], df['Predicted']], label=['Actual', 'Predicted'])\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"S0P5kqYYa15g"},"source":["# Neural Network with replicated rows"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13908,"status":"ok","timestamp":1705476669725,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"xVWUofdVPcZD","outputId":"b96a92ea-35fb-4ee0-ed41-85f0459d4644"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","\n","\n","#------------------------ Load and preprocess the data ------------------------\n","\n","\n","df = pd.read_csv('/content/drive/MyDrive/Sensors/postgres_new_data.csv')\n","\n","# Generate the column names as rv1, rv2, ..., rv1500\n","col_names = [f'rv{i}' for i in range(1, 1501)]\n","\n","# Split the rv column by comma into a list of Series\n","split_series = df['rv'].str.split(',', n=1499, expand=True).apply(pd.Series)\n","\n","# Concatenate the original DataFrame with the split Series\n","df = pd.concat([df, split_series], axis=1)\n","\n","# Rename the split columns\n","df.rename(columns=dict(zip(split_series.columns, col_names)), inplace=True)\n","\n","# Drop the original 'rv' column\n","df.drop('rv', axis=1, inplace=True)\n","\n","# Remove ALL Nan rows\n","df.dropna(axis=0, how='all', inplace=True)\n","\n","# Replicate 4 times class 1 and 5 times class 0\n","df_replicated = pd.concat([df[df['ae_cl'] == 1]] * 4 + [df[df['ae_cl'] == 0]] * 5)\n","\n","# Add the replicated rows to the original DataFrame\n","df = pd.concat([df, df_replicated])\n","\n","print(df.shape)\n","\n","# Check if there are any Nan rows\n","nan_rows = df[df.isnull().any(axis=1)]\n","if nan_rows.empty:\n","    print(\"There are no NaN rows\")\n","else:\n","    print(\"There are NaN rows\")\n","\n","# Check ae_cl count\n","print(df['ae_cl'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fwnLChdPcZE"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Define the features and labels ------------------------\n","\n","\n","\n","X = df.loc[:, 'rv1':'rv1500'].astype(float).values\n","# X = df[col_names].astype(float).values\n","y = df['ae_cl']\n","\n","# Create a mask that is True for non-nan values and False for nan values\n","mask = ~np.isnan(y)\n","\n","# Apply the mask to both X and y\n","X = X[mask]\n","y = y[mask]\n","\n","# Check the count of each class in y\n","print(np.unique(y, return_counts=True))\n","\n","# Convert the data to tensors\n","X_tensor = torch.from_numpy(X)\n","y_tensor = torch.LongTensor(np.squeeze(y.values).astype(int)) # use np.squeeze on the values attribute\n","\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":239,"status":"ok","timestamp":1705490321483,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"pIqKDPfgPcZF"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Define the neural network model ------------------------\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.conv1 = nn.Conv1d(1, 3, 3) # Convolutional layer with 1 input channel, 3 output channels, and filter size 3\n","        self.fc2 = nn.Linear(4494, 3) # Linear layer with 4494 input features and 3 output units\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), 1, -1) # Reshape the input to have a channel dimension\n","        x = torch.relu(self.conv1(x)) # Apply ReLU activation to the convolutional layer\n","        x = x.view(x.size(0), -1) # Flatten the output to have a feature dimension\n","        x = self.fc2(x) # Apply linear transformation to the output layer\n","        return x # Return the logits without softmax\n","\n","\n","# Create an instance of the neural network model\n","model = NeuralNetwork()\n","\n","# Cast X_train and X_test to the same data type as model.fc1.weight\n","X_train = X_train.to(model.conv1.weight.dtype)\n","X_test = X_test.to(model.conv1.weight.dtype)\n","\n","\n","# Assigning more weight to minority classes\n","total = 696 + 1340 + 5000 # Total number of samples\n","weight_0 = total / 696 # Weight for class 0\n","weight_1 = total / 1340 # Weight for class 1\n","weight_2 = total / 5000 # Weight for class 2\n","weight = torch.tensor([weight_0, weight_1, weight_2]) # Tensor of class weights\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss(weight=weight)\n","optimizer = optim.Adam(model.parameters(), lr=0.000001)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":111279,"status":"ok","timestamp":1705490436238,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"y1JqxYHUPcZF","outputId":"49db14c5-7f86-4fa5-96e9-9102e680516f"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Train and evaluate the model ------------------------\n","\n","\n","# Train the model\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    outputs = model(X_train)\n","    loss = criterion(outputs, y_train)\n","    loss.backward()\n","    optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n","\n","\n","# Evaluate the model\n","with torch.no_grad():\n","    train_outputs = model(X_train)\n","    train_predictions = torch.argmax(train_outputs, dim=1)\n","    train_accuracy = (train_predictions == y_train).float().mean()\n","\n","    test_outputs = model(X_test)\n","    test_predictions = torch.argmax(test_outputs, dim=1)\n","    test_accuracy = (test_predictions == y_test).float().mean()\n","\n","\n","print(\"Training Accuracy: {:.2f}%\".format(train_accuracy * 100))\n","print(\"Testing Accuracy: {:.2f}%\".format(test_accuracy * 100))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":751},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1705490439135,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"A7GwX6vDPcZF","outputId":"ec5ce090-05ab-4d87-93cf-2cf293839980"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Analyze predictions ------------------------\n","\n","\n","# Create and print new df with actual and predicted value for test set\n","df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': test_predictions.flatten()})\n","print(df)\n","\n","# Save the dataframe to a CSV file\n","df.to_csv('predictions_cl.csv', index=False)\n","\n","\n","# Calculate difference between actual and predicted values\n","df['Difference'] = (df['Actual'] - df['Predicted'])\n","\n","# Calculate accuracy\n","count = (df['Difference'] == 0.00).sum()\n","print(\"Correct predictions:\", count)\n","print(\"Total predictions:\", len(df))\n","print(\"Accuracy:\", (count / len(df)).round(2))\n","\n","# Check the count of each class in df['Predicted']\n","print(\"Total predictions per class:\", np.unique(df['Predicted'], return_counts=True))\n","\n","# NB the model ALWAYS predicts 2, given the high frequency of its occurence in the training set\n","\n","# Plot actual and predicted values with histogram\n","plt.hist([df['Actual'], df['Predicted']], label=['Actual', 'Predicted'])\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"TpZ4qilOPcZG"},"source":["# Random Forest\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":106137,"status":"ok","timestamp":1705479224725,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"vvZT52--egWb"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","#------------------------ Create and train the model ------------------------\n","\n","# Create and fit a random forest regressor\n","rfr = RandomForestRegressor(n_estimators=100, random_state=42)\n","rfr.fit(X_train, y_train.ravel()) # use ravel to flatten y_train\n","\n","# Make predictions on the test set\n","y_pred = rfr.predict(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":233,"status":"ok","timestamp":1705479257182,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"9SXx8YpJegWb","outputId":"377580f2-f61a-4f91-a6ef-dd723fe9e8e3"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Analyze predictions ------------------------\n","\n","# Evaluate the model performance\n","rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","print(f\"Root Mean Squared Error: {rmse:.2f}\")\n","\n","# MAE\n","mae = mean_absolute_error(y_test, y_pred)\n","print(f\"Mean Absolute Error: {mae:.2f}\")\n","\n","# Accuracy\n","accuracy = rfr.score(X_test, y_test)\n","print(f\"Raw Accuracy: {accuracy:.2f}\")\n","\n","# Create new csv with actual and predicted data\n","df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': np.round(y_pred, 0)})\n","\n","# Add the difference column\n","df['Difference'] = df['Actual'] - df['Predicted']\n","\n","# Calculate accuracy of the model after rounding to the nearest integer\n","accuracy = (df['Difference'] == 0.00).sum() / len(df)\n","print(f\"Adjusted Accuracy: {accuracy:.2f}\")\n","\n","# Save the dataframe to a CSV file\n","df.to_csv('predictions_rf.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"executionInfo":{"elapsed":640,"status":"ok","timestamp":1705479262711,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"jW2wixnCegWc","outputId":"c8923225-9d23-487f-a03d-75e4debd8d8e"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Plot predictions ------------------------\n","\n","# Plot actual and predicted values with histogram\n","plt.hist([df['Actual'], df['Predicted']], label=['Actual', 'Predicted'])\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cI0Y2iRyFTS"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["#------------------------ Predict single  ------------------------\n","\n","\n","# Convert the row into a numpy array and reshape it to have the same shape as X_train\n","#row = np.array(row).reshape(1, 1500)\n","\n","# Predict the class of the row using the model\n","#cl = int(rfr.predict(row))\n","\n","# Print the result\n","#print(f\"The predicted class of the row is {cl}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1705489903657,"user":{"displayName":"Alessio Leodori","userId":"07295113092427212243"},"user_tz":-60},"id":"uQxqvNlJHobB","outputId":"c2d61818-9d22-4e6e-ec46-a341f5354d38"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'py_Django' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n py_Django ipykernel --update-deps --force-reinstall'"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   slope\n","0    1.0\n","1    2.0\n","2    3.0\n","3    4.0\n","4    5.0\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LinearRegression\n","\n","# Create a sample DataFrame\n","data = {'c1': [1, 2, 3, 4, 5],\n","        'c2': [2, 4, 6, 8, 10],\n","        'c3': [3, 6, 9, 12, 15],\n","        'c4': [4, 8, 12, 16, 20],\n","        'c5': [5, 10, 15, 20, 25],\n","        }\n","\n","df = pd.DataFrame(data)\n","\n","# Specify the columns to include in the linear regression (exclude 'c1' and 'c2')\n","columns_to_include = ['c3', 'c4', 'c5']\n","\n","# Create an instance of LinearRegression\n","model = LinearRegression()\n","\n","# Function to get coefficient for each row\n","def get_coeff(row, model=model):\n","    # Select only relevant columns\n","    row = row.loc[columns_to_include]\n","    \n","    # Drop NaN values\n","    row = row.dropna()\n","    \n","    if len(row) > 1:  # Check if there are enough data points for regression\n","        X = np.arange(len(row)).reshape(-1, 1)\n","        y = row.values.reshape(-1, 1)\n","        model.fit(X, y)\n","        slope = model.coef_[0][0]\n","        return slope\n","    else:\n","        return np.nan  # Return NaN if there are not enough data points\n","\n","# Apply the function to each row to get only the slope values\n","df['slope'] = df.apply(get_coeff, axis=1)\n","\n","print(df[['slope']])\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPhPH9KC52rl2jSW0Xjx3WV","gpuType":"T4","mount_file_id":"12RBqsdsW6ybtYghxXZflWeEbTXLfT92g","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}
