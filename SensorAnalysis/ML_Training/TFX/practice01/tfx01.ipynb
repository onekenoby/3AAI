{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "from tfx.components import CsvExampleGen, StatisticsGen, SchemaGen, ExampleValidator, Transform, Trainer, InfraValidator\n",
    "from tfx.components.example_gen import utils\n",
    "from transformers import AutoTokenizer\n",
    "from typing import List\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tfx.proto import example_gen_pb2  # Import from tfx.proto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths\n",
    "_pipeline_name = \"qa_pipeline\"\n",
    "_data_path = \"./data/\"\n",
    "_speech_data_file = \"sjs.txt\"  # Your speech file\n",
    "_pipeline_root = os.path.join(\"tfx_pipelines\", _pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize TFX interactive context\n",
    "context = InteractiveContext(pipeline_root=_pipeline_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: ExampleGen - Read the speech text file\n",
    "example_gen = CsvExampleGen(\n",
    "    input_base=_data_path,\n",
    "    input_config=example_gen_pb2.Input(splits=[\n",
    "        example_gen_pb2.Input.Split(name='train', pattern=_speech_data_file)\n",
    "    ]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run ExampleGen\n",
    "context.run(example_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: StatisticsGen - Generate statistics for the dataset\n",
    "statistics_gen = StatisticsGen(\n",
    "    examples=example_gen.outputs['examples']\n",
    ")\n",
    "\n",
    "# Run StatisticsGen\n",
    "context.run(statistics_gen)\n",
    "\n",
    "# Step 3: SchemaGen - Infer schema from statistics\n",
    "schema_gen = SchemaGen(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    ")\n",
    "\n",
    "# Run SchemaGen\n",
    "context.run(schema_gen)\n",
    "\n",
    "# Step 4: ExampleValidator - Validate examples based on the schema\n",
    "example_validator = ExampleValidator(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    ")\n",
    "\n",
    "# Run ExampleValidator\n",
    "context.run(example_validator)\n",
    "\n",
    "# Step 5: Transform - Tokenize input text and generate questions\n",
    "@tft.transform_fn\n",
    "def preprocessing_fn(inputs):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "    # Tokenize the input text\n",
    "    input_tokens = tokenizer(\n",
    "        inputs['text'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "    # Flatten the input tokens\n",
    "    flat_tokens = {key: tf.reshape(tensor, [-1]) for key, tensor in input_tokens.items()}\n",
    "\n",
    "    return flat_tokens\n",
    "\n",
    "transform = Transform(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    module_file=os.path.abspath(\"transform_module.py\"),  # Save the transform_fn to a file\n",
    "    preprocessing_fn=preprocessing_fn,\n",
    ")\n",
    "\n",
    "# Run Transform\n",
    "context.run(transform)\n",
    "\n",
    "# Step 6: Trainer - Train the model\n",
    "trainer = Trainer(\n",
    "    module_file=os.path.abspath(\"train_module.py\"),  # Save the trainer_fn to a file\n",
    "    custom_executor_spec=trainer_pb2.ExecutorSpec(\n",
    "        python_executor_spec=trainer_pb2.PythonExecutorSpec(\n",
    "            classname='GenericExecutor'\n",
    "        )\n",
    "    ),\n",
    "    examples=transform.outputs['transformed_examples'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    train_args=trainer_pb2.TrainArgs(),\n",
    "    eval_args=trainer_pb2.EvalArgs(),\n",
    ")\n",
    "\n",
    "# Run Trainer\n",
    "context.run(trainer)\n",
    "\n",
    "# Step 7: InfraValidator - Validate the serving infrastructure\n",
    "infra_validator = InfraValidator(\n",
    "    model=trainer.outputs['model'],\n",
    "    serving_spec=infra_validator_pb2.ServingSpec(\n",
    "        tensorflow_serving=infra_validator_pb2.TensorFlowServing(\n",
    "            tags=[\"latest\"]\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Run InfraValidator\n",
    "context.run(infra_validator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "from tfx.proto import example_gen_pb2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming the notebook is in the project directory\n",
    "_project_dir = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\stefa\\\\3AInformatica_Prjs\\\\009.sensors_data_analysis\\\\3AAI\\\\SensorAnalysis\\\\ML_Training\\\\TFX\\\\practice01'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_project_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_data_path = os.path.join(_project_dir, \"./data\") = os.path.join(_project_dir, \"./data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_speech_data_file = \"sjs.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: c:\\Users\\stefa\\3AInformatica_Prjs\\009.sensors_data_analysis\\3AAI\\SensorAnalysis\\ML_Training\\TFX\\practice01\\data\\sjs.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the file exists\n",
    "file_path = os.path.join(_data_path, _speech_data_file)\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"File not found: {file_path}\")\n",
    "else:\n",
    "    print(f\"File found: {file_path}\")\n",
    "_data_path = \"./data/\"\n",
    "_speech_data_file = \"sjs.txt\"  # Your speech file\n",
    "_pipeline_root = os.path.join(\"tfx_pipelines\", _pipeline_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have created an InteractiveContext named 'context'\n",
    "context = InteractiveContext()\n",
    "\n",
    "# Run ExampleGen\n",
    "example_gen = CsvExampleGen(\n",
    "    input_base=_data_path,\n",
    "    input_config=example_gen_pb2.Input(splits=[\n",
    "        example_gen_pb2.Input.Split(name='train', pattern=_speech_data_file)\n",
    "    ]),\n",
    ")\n",
    "context.run(example_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3aai_tfx37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
